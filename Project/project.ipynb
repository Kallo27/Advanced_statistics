{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"./aux.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Six-label dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously introduced, the first dataset we analyze is composed of documents with assigned one of six labels, which indicate the level of truthness of each document, and a tag that indicates the main topics of the document. We upload the data as a dataframe using the `read.csv()` function, naming the three columns. First of all, as previously explained, we change the labels in order to make their meaning consistent with their value. Secondly, we save the unique labels and tags in two vectors, which will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Label</th><th scope=col>Text</th><th scope=col>Tag</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>Says the Annies List political group supports third-trimester abortions on demand.                                                                         </td><td>abortion                          </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>3</td><td>When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.              </td><td>energy,history,job-accomplishments</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>4</td><td>Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"                                                  </td><td>foreign-policy                    </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>Health care reform legislation is likely to mandate free sex change surgeries.                                                                             </td><td>health-care                       </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>3</td><td>The economic turnaround started at the end of my term.                                                                                                     </td><td>economy,jobs                      </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>5</td><td>The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.</td><td>education                         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Label & Text & Tag\\\\\n",
       "  & <dbl> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & Says the Annies List political group supports third-trimester abortions on demand.                                                                          & abortion                          \\\\\n",
       "\t2 & 3 & When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.               & energy,history,job-accomplishments\\\\\n",
       "\t3 & 4 & Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"                                                   & foreign-policy                    \\\\\n",
       "\t4 & 1 & Health care reform legislation is likely to mandate free sex change surgeries.                                                                              & health-care                       \\\\\n",
       "\t5 & 3 & The economic turnaround started at the end of my term.                                                                                                      & economy,jobs                      \\\\\n",
       "\t6 & 5 & The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades. & education                         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 3\n",
       "\n",
       "| <!--/--> | Label &lt;dbl&gt; | Text &lt;chr&gt; | Tag &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | Says the Annies List political group supports third-trimester abortions on demand.                                                                          | abortion                           |\n",
       "| 2 | 3 | When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.               | energy,history,job-accomplishments |\n",
       "| 3 | 4 | Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"                                                   | foreign-policy                     |\n",
       "| 4 | 1 | Health care reform legislation is likely to mandate free sex change surgeries.                                                                              | health-care                        |\n",
       "| 5 | 3 | The economic turnaround started at the end of my term.                                                                                                      | economy,jobs                       |\n",
       "| 6 | 5 | The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades. | education                          |\n",
       "\n"
      ],
      "text/plain": [
       "  Label\n",
       "1 1    \n",
       "2 3    \n",
       "3 4    \n",
       "4 1    \n",
       "5 3    \n",
       "6 5    \n",
       "  Text                                                                                                                                                       \n",
       "1 Says the Annies List political group supports third-trimester abortions on demand.                                                                         \n",
       "2 When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.              \n",
       "3 Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"                                                  \n",
       "4 Health care reform legislation is likely to mandate free sex change surgeries.                                                                             \n",
       "5 The economic turnaround started at the end of my term.                                                                                                     \n",
       "6 The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.\n",
       "  Tag                               \n",
       "1 abortion                          \n",
       "2 energy,history,job-accomplishments\n",
       "3 foreign-policy                    \n",
       "4 health-care                       \n",
       "5 economy,jobs                      \n",
       "6 education                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset <- read.csv(\"six_label_dataset.csv\", col.names = c(\"Label\", \"Text\", \"Tag\"))\n",
    "dataset$Label <- change_labels(dataset$Label)\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0</li><li>1</li><li>2</li><li>3</li><li>4</li><li>5</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 4\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 1\n",
       "3. 2\n",
       "4. 3\n",
       "5. 4\n",
       "6. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 1 2 3 4 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes <- as.integer(sort(unique(dataset$Label)))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'10-news-tampa-bay'</li><li>'abc-news-week'</li><li>'abortion'</li><li>'afghanistan'</li><li>'after-the-fact'</li><li>'agriculture'</li><li>'Alcohol'</li><li>'animals'</li><li>'autism'</li><li>'bankruptcy'</li><li>'baseball'</li><li>'bipartisanship'</li><li>'bush-administration'</li><li>'campaign-advertising'</li><li>'campaign-finance'</li><li>'candidates-biography'</li><li>'cap-and-trade'</li><li>'census'</li><li>'children'</li><li>'china'</li><li>'city-budget'</li><li>'city-government'</li><li>'civil-rights'</li><li>'climate-change'</li><li>'colbert-report'</li><li>'congress'</li><li>'congressional-rules'</li><li>'consumer-safety'</li><li>'corporations'</li><li>'corrections-and-updates'</li><li>'county-budget'</li><li>'county-government'</li><li>'crime'</li><li>'criminal-justice'</li><li>'death-penalty'</li><li>'debates'</li><li>'debt'</li><li>'deficit'</li><li>'disability'</li><li>'diversity'</li><li>'drugs'</li><li>'ebola'</li><li>'economy'</li><li>'education'</li><li>'elections'</li><li>'energy'</li><li>'environment'</li><li>'ethics'</li><li>'fake-news'</li><li>'families'</li><li>'federal-budget'</li><li>'financial-regulation'</li><li>'fires'</li><li>'florida'</li><li>'florida-amendments'</li><li>'food'</li><li>'food-safety'</li><li>'foreign-policy'</li><li>'gambling'</li><li>'gas-prices'</li><li>'gays-and-lesbians'</li><li>'government-efficiency'</li><li>'government-regulation'</li><li>'guns'</li><li>'health-care'</li><li>'history'</li><li>'homeland-security'</li><li>'homeless'</li><li>'housing'</li><li>'human-rights'</li><li>'hunger'</li><li>'immigration'</li><li>'income'</li><li>'infrastructure'</li><li>'iraq'</li><li>'islam'</li><li>'israel'</li><li>'job-accomplishments'</li><li>'jobs'</li><li>'kagan-nomination'</li><li>'labor'</li><li>'legal-issues'</li><li>'lottery'</li><li>'marijuana'</li><li>'market-regulation'</li><li>'marriage'</li><li>'medicaid'</li><li>'medicare'</li><li>'message-machine'</li><li>'message-machine-2012'</li><li>'message-machine-2014'</li><li>'military'</li><li>'natural-disasters'</li><li>'new-hampshire-2012'</li><li>'nuclear'</li><li>'obama-birth-certificate'</li><li>'occupy-wall-street'</li><li>'oil-spill'</li><li>'patriotism'</li><li>'pensions'</li><li>'polls'</li><li>'pop-culture'</li><li>'population'</li><li>'poverty'</li><li>'privacy'</li><li>'public-health'</li><li>'public-safety'</li><li>'public-service'</li><li>'pundits'</li><li>'recreation'</li><li>'redistricting'</li><li>'religion'</li><li>'retirement'</li><li>'science'</li><li>'sexuality'</li><li>'small-business'</li><li>'social-security'</li><li>'sotomayor-nomination'</li><li>'space'</li><li>'sports'</li><li>'state-budget'</li><li>'state-finances'</li><li>'states'</li><li>'stimulus'</li><li>'supreme-court'</li><li>'taxes'</li><li>'technology'</li><li>'terrorism'</li><li>'tourism'</li><li>'trade'</li><li>'transparency'</li><li>'transportation'</li><li>'unions'</li><li>'urban'</li><li>'veterans'</li><li>'voting-record'</li><li>'water'</li><li>'wealth'</li><li>'weather'</li><li>'welfare'</li><li>'women'</li><li>'workers'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '10-news-tampa-bay'\n",
       "\\item 'abc-news-week'\n",
       "\\item 'abortion'\n",
       "\\item 'afghanistan'\n",
       "\\item 'after-the-fact'\n",
       "\\item 'agriculture'\n",
       "\\item 'Alcohol'\n",
       "\\item 'animals'\n",
       "\\item 'autism'\n",
       "\\item 'bankruptcy'\n",
       "\\item 'baseball'\n",
       "\\item 'bipartisanship'\n",
       "\\item 'bush-administration'\n",
       "\\item 'campaign-advertising'\n",
       "\\item 'campaign-finance'\n",
       "\\item 'candidates-biography'\n",
       "\\item 'cap-and-trade'\n",
       "\\item 'census'\n",
       "\\item 'children'\n",
       "\\item 'china'\n",
       "\\item 'city-budget'\n",
       "\\item 'city-government'\n",
       "\\item 'civil-rights'\n",
       "\\item 'climate-change'\n",
       "\\item 'colbert-report'\n",
       "\\item 'congress'\n",
       "\\item 'congressional-rules'\n",
       "\\item 'consumer-safety'\n",
       "\\item 'corporations'\n",
       "\\item 'corrections-and-updates'\n",
       "\\item 'county-budget'\n",
       "\\item 'county-government'\n",
       "\\item 'crime'\n",
       "\\item 'criminal-justice'\n",
       "\\item 'death-penalty'\n",
       "\\item 'debates'\n",
       "\\item 'debt'\n",
       "\\item 'deficit'\n",
       "\\item 'disability'\n",
       "\\item 'diversity'\n",
       "\\item 'drugs'\n",
       "\\item 'ebola'\n",
       "\\item 'economy'\n",
       "\\item 'education'\n",
       "\\item 'elections'\n",
       "\\item 'energy'\n",
       "\\item 'environment'\n",
       "\\item 'ethics'\n",
       "\\item 'fake-news'\n",
       "\\item 'families'\n",
       "\\item 'federal-budget'\n",
       "\\item 'financial-regulation'\n",
       "\\item 'fires'\n",
       "\\item 'florida'\n",
       "\\item 'florida-amendments'\n",
       "\\item 'food'\n",
       "\\item 'food-safety'\n",
       "\\item 'foreign-policy'\n",
       "\\item 'gambling'\n",
       "\\item 'gas-prices'\n",
       "\\item 'gays-and-lesbians'\n",
       "\\item 'government-efficiency'\n",
       "\\item 'government-regulation'\n",
       "\\item 'guns'\n",
       "\\item 'health-care'\n",
       "\\item 'history'\n",
       "\\item 'homeland-security'\n",
       "\\item 'homeless'\n",
       "\\item 'housing'\n",
       "\\item 'human-rights'\n",
       "\\item 'hunger'\n",
       "\\item 'immigration'\n",
       "\\item 'income'\n",
       "\\item 'infrastructure'\n",
       "\\item 'iraq'\n",
       "\\item 'islam'\n",
       "\\item 'israel'\n",
       "\\item 'job-accomplishments'\n",
       "\\item 'jobs'\n",
       "\\item 'kagan-nomination'\n",
       "\\item 'labor'\n",
       "\\item 'legal-issues'\n",
       "\\item 'lottery'\n",
       "\\item 'marijuana'\n",
       "\\item 'market-regulation'\n",
       "\\item 'marriage'\n",
       "\\item 'medicaid'\n",
       "\\item 'medicare'\n",
       "\\item 'message-machine'\n",
       "\\item 'message-machine-2012'\n",
       "\\item 'message-machine-2014'\n",
       "\\item 'military'\n",
       "\\item 'natural-disasters'\n",
       "\\item 'new-hampshire-2012'\n",
       "\\item 'nuclear'\n",
       "\\item 'obama-birth-certificate'\n",
       "\\item 'occupy-wall-street'\n",
       "\\item 'oil-spill'\n",
       "\\item 'patriotism'\n",
       "\\item 'pensions'\n",
       "\\item 'polls'\n",
       "\\item 'pop-culture'\n",
       "\\item 'population'\n",
       "\\item 'poverty'\n",
       "\\item 'privacy'\n",
       "\\item 'public-health'\n",
       "\\item 'public-safety'\n",
       "\\item 'public-service'\n",
       "\\item 'pundits'\n",
       "\\item 'recreation'\n",
       "\\item 'redistricting'\n",
       "\\item 'religion'\n",
       "\\item 'retirement'\n",
       "\\item 'science'\n",
       "\\item 'sexuality'\n",
       "\\item 'small-business'\n",
       "\\item 'social-security'\n",
       "\\item 'sotomayor-nomination'\n",
       "\\item 'space'\n",
       "\\item 'sports'\n",
       "\\item 'state-budget'\n",
       "\\item 'state-finances'\n",
       "\\item 'states'\n",
       "\\item 'stimulus'\n",
       "\\item 'supreme-court'\n",
       "\\item 'taxes'\n",
       "\\item 'technology'\n",
       "\\item 'terrorism'\n",
       "\\item 'tourism'\n",
       "\\item 'trade'\n",
       "\\item 'transparency'\n",
       "\\item 'transportation'\n",
       "\\item 'unions'\n",
       "\\item 'urban'\n",
       "\\item 'veterans'\n",
       "\\item 'voting-record'\n",
       "\\item 'water'\n",
       "\\item 'wealth'\n",
       "\\item 'weather'\n",
       "\\item 'welfare'\n",
       "\\item 'women'\n",
       "\\item 'workers'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '10-news-tampa-bay'\n",
       "2. 'abc-news-week'\n",
       "3. 'abortion'\n",
       "4. 'afghanistan'\n",
       "5. 'after-the-fact'\n",
       "6. 'agriculture'\n",
       "7. 'Alcohol'\n",
       "8. 'animals'\n",
       "9. 'autism'\n",
       "10. 'bankruptcy'\n",
       "11. 'baseball'\n",
       "12. 'bipartisanship'\n",
       "13. 'bush-administration'\n",
       "14. 'campaign-advertising'\n",
       "15. 'campaign-finance'\n",
       "16. 'candidates-biography'\n",
       "17. 'cap-and-trade'\n",
       "18. 'census'\n",
       "19. 'children'\n",
       "20. 'china'\n",
       "21. 'city-budget'\n",
       "22. 'city-government'\n",
       "23. 'civil-rights'\n",
       "24. 'climate-change'\n",
       "25. 'colbert-report'\n",
       "26. 'congress'\n",
       "27. 'congressional-rules'\n",
       "28. 'consumer-safety'\n",
       "29. 'corporations'\n",
       "30. 'corrections-and-updates'\n",
       "31. 'county-budget'\n",
       "32. 'county-government'\n",
       "33. 'crime'\n",
       "34. 'criminal-justice'\n",
       "35. 'death-penalty'\n",
       "36. 'debates'\n",
       "37. 'debt'\n",
       "38. 'deficit'\n",
       "39. 'disability'\n",
       "40. 'diversity'\n",
       "41. 'drugs'\n",
       "42. 'ebola'\n",
       "43. 'economy'\n",
       "44. 'education'\n",
       "45. 'elections'\n",
       "46. 'energy'\n",
       "47. 'environment'\n",
       "48. 'ethics'\n",
       "49. 'fake-news'\n",
       "50. 'families'\n",
       "51. 'federal-budget'\n",
       "52. 'financial-regulation'\n",
       "53. 'fires'\n",
       "54. 'florida'\n",
       "55. 'florida-amendments'\n",
       "56. 'food'\n",
       "57. 'food-safety'\n",
       "58. 'foreign-policy'\n",
       "59. 'gambling'\n",
       "60. 'gas-prices'\n",
       "61. 'gays-and-lesbians'\n",
       "62. 'government-efficiency'\n",
       "63. 'government-regulation'\n",
       "64. 'guns'\n",
       "65. 'health-care'\n",
       "66. 'history'\n",
       "67. 'homeland-security'\n",
       "68. 'homeless'\n",
       "69. 'housing'\n",
       "70. 'human-rights'\n",
       "71. 'hunger'\n",
       "72. 'immigration'\n",
       "73. 'income'\n",
       "74. 'infrastructure'\n",
       "75. 'iraq'\n",
       "76. 'islam'\n",
       "77. 'israel'\n",
       "78. 'job-accomplishments'\n",
       "79. 'jobs'\n",
       "80. 'kagan-nomination'\n",
       "81. 'labor'\n",
       "82. 'legal-issues'\n",
       "83. 'lottery'\n",
       "84. 'marijuana'\n",
       "85. 'market-regulation'\n",
       "86. 'marriage'\n",
       "87. 'medicaid'\n",
       "88. 'medicare'\n",
       "89. 'message-machine'\n",
       "90. 'message-machine-2012'\n",
       "91. 'message-machine-2014'\n",
       "92. 'military'\n",
       "93. 'natural-disasters'\n",
       "94. 'new-hampshire-2012'\n",
       "95. 'nuclear'\n",
       "96. 'obama-birth-certificate'\n",
       "97. 'occupy-wall-street'\n",
       "98. 'oil-spill'\n",
       "99. 'patriotism'\n",
       "100. 'pensions'\n",
       "101. 'polls'\n",
       "102. 'pop-culture'\n",
       "103. 'population'\n",
       "104. 'poverty'\n",
       "105. 'privacy'\n",
       "106. 'public-health'\n",
       "107. 'public-safety'\n",
       "108. 'public-service'\n",
       "109. 'pundits'\n",
       "110. 'recreation'\n",
       "111. 'redistricting'\n",
       "112. 'religion'\n",
       "113. 'retirement'\n",
       "114. 'science'\n",
       "115. 'sexuality'\n",
       "116. 'small-business'\n",
       "117. 'social-security'\n",
       "118. 'sotomayor-nomination'\n",
       "119. 'space'\n",
       "120. 'sports'\n",
       "121. 'state-budget'\n",
       "122. 'state-finances'\n",
       "123. 'states'\n",
       "124. 'stimulus'\n",
       "125. 'supreme-court'\n",
       "126. 'taxes'\n",
       "127. 'technology'\n",
       "128. 'terrorism'\n",
       "129. 'tourism'\n",
       "130. 'trade'\n",
       "131. 'transparency'\n",
       "132. 'transportation'\n",
       "133. 'unions'\n",
       "134. 'urban'\n",
       "135. 'veterans'\n",
       "136. 'voting-record'\n",
       "137. 'water'\n",
       "138. 'wealth'\n",
       "139. 'weather'\n",
       "140. 'welfare'\n",
       "141. 'women'\n",
       "142. 'workers'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] \"10-news-tampa-bay\"       \"abc-news-week\"          \n",
       "  [3] \"abortion\"                \"afghanistan\"            \n",
       "  [5] \"after-the-fact\"          \"agriculture\"            \n",
       "  [7] \"Alcohol\"                 \"animals\"                \n",
       "  [9] \"autism\"                  \"bankruptcy\"             \n",
       " [11] \"baseball\"                \"bipartisanship\"         \n",
       " [13] \"bush-administration\"     \"campaign-advertising\"   \n",
       " [15] \"campaign-finance\"        \"candidates-biography\"   \n",
       " [17] \"cap-and-trade\"           \"census\"                 \n",
       " [19] \"children\"                \"china\"                  \n",
       " [21] \"city-budget\"             \"city-government\"        \n",
       " [23] \"civil-rights\"            \"climate-change\"         \n",
       " [25] \"colbert-report\"          \"congress\"               \n",
       " [27] \"congressional-rules\"     \"consumer-safety\"        \n",
       " [29] \"corporations\"            \"corrections-and-updates\"\n",
       " [31] \"county-budget\"           \"county-government\"      \n",
       " [33] \"crime\"                   \"criminal-justice\"       \n",
       " [35] \"death-penalty\"           \"debates\"                \n",
       " [37] \"debt\"                    \"deficit\"                \n",
       " [39] \"disability\"              \"diversity\"              \n",
       " [41] \"drugs\"                   \"ebola\"                  \n",
       " [43] \"economy\"                 \"education\"              \n",
       " [45] \"elections\"               \"energy\"                 \n",
       " [47] \"environment\"             \"ethics\"                 \n",
       " [49] \"fake-news\"               \"families\"               \n",
       " [51] \"federal-budget\"          \"financial-regulation\"   \n",
       " [53] \"fires\"                   \"florida\"                \n",
       " [55] \"florida-amendments\"      \"food\"                   \n",
       " [57] \"food-safety\"             \"foreign-policy\"         \n",
       " [59] \"gambling\"                \"gas-prices\"             \n",
       " [61] \"gays-and-lesbians\"       \"government-efficiency\"  \n",
       " [63] \"government-regulation\"   \"guns\"                   \n",
       " [65] \"health-care\"             \"history\"                \n",
       " [67] \"homeland-security\"       \"homeless\"               \n",
       " [69] \"housing\"                 \"human-rights\"           \n",
       " [71] \"hunger\"                  \"immigration\"            \n",
       " [73] \"income\"                  \"infrastructure\"         \n",
       " [75] \"iraq\"                    \"islam\"                  \n",
       " [77] \"israel\"                  \"job-accomplishments\"    \n",
       " [79] \"jobs\"                    \"kagan-nomination\"       \n",
       " [81] \"labor\"                   \"legal-issues\"           \n",
       " [83] \"lottery\"                 \"marijuana\"              \n",
       " [85] \"market-regulation\"       \"marriage\"               \n",
       " [87] \"medicaid\"                \"medicare\"               \n",
       " [89] \"message-machine\"         \"message-machine-2012\"   \n",
       " [91] \"message-machine-2014\"    \"military\"               \n",
       " [93] \"natural-disasters\"       \"new-hampshire-2012\"     \n",
       " [95] \"nuclear\"                 \"obama-birth-certificate\"\n",
       " [97] \"occupy-wall-street\"      \"oil-spill\"              \n",
       " [99] \"patriotism\"              \"pensions\"               \n",
       "[101] \"polls\"                   \"pop-culture\"            \n",
       "[103] \"population\"              \"poverty\"                \n",
       "[105] \"privacy\"                 \"public-health\"          \n",
       "[107] \"public-safety\"           \"public-service\"         \n",
       "[109] \"pundits\"                 \"recreation\"             \n",
       "[111] \"redistricting\"           \"religion\"               \n",
       "[113] \"retirement\"              \"science\"                \n",
       "[115] \"sexuality\"               \"small-business\"         \n",
       "[117] \"social-security\"         \"sotomayor-nomination\"   \n",
       "[119] \"space\"                   \"sports\"                 \n",
       "[121] \"state-budget\"            \"state-finances\"         \n",
       "[123] \"states\"                  \"stimulus\"               \n",
       "[125] \"supreme-court\"           \"taxes\"                  \n",
       "[127] \"technology\"              \"terrorism\"              \n",
       "[129] \"tourism\"                 \"trade\"                  \n",
       "[131] \"transparency\"            \"transportation\"         \n",
       "[133] \"unions\"                  \"urban\"                  \n",
       "[135] \"veterans\"                \"voting-record\"          \n",
       "[137] \"water\"                   \"wealth\"                 \n",
       "[139] \"weather\"                 \"welfare\"                \n",
       "[141] \"women\"                   \"workers\"                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args <- sort(unique(unlist(strsplit(dataset$Tag, \",\"))))\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After an initial look to the dataset, we can see how many unique words the dataset contains before cleaning it. Then, after applying the `clean()` function and performing lemmatization and stemming, we can see how much the vocabulary has been reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "21678"
      ],
      "text/latex": [
       "21678"
      ],
      "text/markdown": [
       "21678"
      ],
      "text/plain": [
       "[1] 21678"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_voc <- length(get_vocabulary_six(dataset$Text, threshold = 1))\n",
    "len_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dataset$Text <- clean(dataset$Text)\n",
    "dataset <- clean_empty_rows(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "5142"
      ],
      "text/latex": [
       "5142"
      ],
      "text/markdown": [
       "5142"
      ],
      "text/plain": [
       "[1] 5142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_voc_cleaned <- length(get_vocabulary_six(dataset$Text, threshold = 1))\n",
    "len_voc_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "2074"
      ],
      "text/latex": [
       "2074"
      ],
      "text/markdown": [
       "2074"
      ],
      "text/plain": [
       "[1] 2074"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_voc_cleaned <- length(get_vocabulary_six(dataset$Text, threshold = 5))\n",
    "len_voc_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the cleaning process reduces a lot the total number of words that are actually unique in our dataset; in particular we get that, using the previously presented techniques for stemming and lemmatizing, the final vocabulary is only 23.7% of the initial vocabulary. If we include also a frequency check, choosing a threshold greater than 1, we are able to reduce the dimension of the vocabulary even more; for example, for `threshold = 5`, the final vocabulary is only 9.6% of the initial vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the preprocessing of the dataset, we are ready to train our Multinomial Naive Bayes model; the first thing to do is to divide the whole dataset in training set, validation set and test set, in order to tune the hyper-parameter of the model annd study its accuracy on unseen data. Before the division we randomly permutate the dataset, in order to remove possible correlation between consecutive documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "seventy_percent <- floor(length(dataset$Text) * 0.7)\n",
    "eightyfive_percent <- floor(length(dataset$Text) * 0.85)\n",
    "n <- nrow(dataset)\n",
    "\n",
    "dataset <- dataset[sample(n), ]\n",
    "\n",
    "training_set <- dataset[1:seventy_percent, ]\n",
    "validation_set <- dataset[(seventy_percent + 1):eightyfive_percent, ]\n",
    "test_set <- dataset[(eightyfive_percent + 1):n, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we consider `threshold = 3` as an example; later in the notebook we proceed to a tuning of this parameter using the validation set and then choosing the model that has the best accuracy on it. After the training, the output of the model are presented to give an idea of how things work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model <- train_multinomial_nb(classes, training_set, threshold = 3, type = \"Six\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [1] \"2\"               \"3\"               \"4\"               \"5\"              \n",
      "   [5] \"6\"               \"9\"               \"abil\"            \"abl\"            \n",
      "   [9] \"abolish\"         \"abort\"           \"absente\"         \"absolut\"        \n",
      "  [13] \"abus\"            \"academ\"          \"academi\"         \"accept\"         \n",
      "  [17] \"access\"          \"accid\"           \"accord\"          \"account\"        \n",
      "  [21] \"accumul\"         \"accus\"           \"achiev\"          \"acknowledg\"     \n",
      "  [25] \"acorn\"           \"acr\"             \"across\"          \"act\"            \n",
      "  [29] \"action\"          \"activ\"           \"activist\"        \"actual\"         \n",
      "  [33] \"ad\"              \"add\"             \"addict\"          \"addit\"          \n",
      "  [37] \"address\"         \"adjust\"          \"administ\"        \"administr\"      \n",
      "  [41] \"admir\"           \"admiss\"          \"admit\"           \"adopt\"          \n",
      "  [45] \"adult\"           \"advanc\"          \"advantag\"        \"advertis\"       \n",
      "  [49] \"advis\"           \"advisor\"         \"advisori\"        \"advoc\"          \n",
      "  [53] \"affair\"          \"affect\"          \"afford\"          \"afraid\"         \n",
      "  [57] \"age\"             \"agenc\"           \"agendum\"         \"agent\"          \n",
      "  [61] \"aggress\"         \"ago\"             \"agre\"            \"agreement\"      \n",
      "  [65] \"agricultur\"      \"ahead\"           \"aid\"             \"aim\"            \n",
      "  [69] \"air\"             \"aircraft\"        \"airplan\"         \"airport\"        \n",
      "  [73] \"alcohol\"         \"alien\"           \"alleg\"           \"alli\"           \n",
      "  [77] \"allow\"           \"almost\"          \"alon\"            \"along\"          \n",
      "  [81] \"alreadi\"         \"also\"            \"altern\"          \"alway\"          \n",
      "  [85] \"amaz\"            \"ambassador\"      \"amend\"           \"ammunit\"        \n",
      "  [89] \"amnesti\"         \"among\"           \"amount\"          \"analysi\"        \n",
      "  [93] \"analyst\"         \"anchor\"          \"angl\"            \"anim\"           \n",
      "  [97] \"anniversari\"     \"announc\"         \"annual\"          \"anoth\"          \n",
      " [101] \"answer\"          \"ant\"             \"anybodi\"         \"anymor\"         \n",
      " [105] \"anyon\"           \"anyth\"           \"anytim\"          \"anywher\"        \n",
      " [109] \"apolog\"          \"appar\"           \"appeal\"          \"appear\"         \n",
      " [113] \"appl\"            \"appli\"           \"applic\"          \"appoint\"        \n",
      " [117] \"appointe\"        \"apprais\"         \"apprehend\"       \"approach\"       \n",
      " [121] \"appropri\"        \"approv\"          \"approxim\"        \"area\"           \n",
      " [125] \"arena\"           \"argument\"        \"arm\"             \"armi\"           \n",
      " [129] \"armor\"           \"around\"          \"arrest\"          \"art\"            \n",
      " [133] \"ask\"             \"assault\"         \"assembl\"         \"assess\"         \n",
      " [137] \"assist\"          \"associ\"          \"asthma\"          \"attack\"         \n",
      " [141] \"attempt\"         \"attend\"          \"attent\"          \"attitud\"        \n",
      " [145] \"attorney\"        \"attract\"         \"attribut\"        \"audienc\"        \n",
      " [149] \"audit\"           \"auditor\"         \"august\"          \"author\"         \n",
      " [153] \"auto\"            \"automat\"         \"automobil\"       \"avail\"          \n",
      " [157] \"averag\"          \"avoid\"           \"award\"           \"away\"           \n",
      " [161] \"babi\"            \"back\"            \"background\"      \"backlog\"        \n",
      " [165] \"backroom\"        \"bad\"             \"bag\"             \"bail\"           \n",
      " [169] \"bailey\"          \"bailout\"         \"balanc\"          \"balloon\"        \n",
      " [173] \"ballot\"          \"ban\"             \"bank\"            \"bankrupt\"       \n",
      " [177] \"bankruptci\"      \"bar\"             \"bare\"            \"bargain\"        \n",
      " [181] \"barrel\"          \"barrow\"          \"base\"            \"basebal\"        \n",
      " [185] \"basi\"            \"basic\"           \"bathroom\"        \"battl\"          \n",
      " [189] \"battlefield\"     \"bay\"             \"beach\"           \"bear\"           \n",
      " [193] \"beat\"            \"becom\"           \"bed\"             \"beef\"           \n",
      " [197] \"beer\"            \"begin\"           \"behalf\"          \"behavior\"       \n",
      " [201] \"behind\"          \"belief\"          \"believ\"          \"belong\"         \n",
      " [205] \"beneficiari\"     \"benefit\"         \"beyond\"          \"bibl\"           \n",
      " [209] \"bicycl\"          \"bid\"             \"big\"             \"bike\"           \n",
      " [213] \"bill\"            \"billion\"         \"billionair\"      \"bin\"            \n",
      " [217] \"bipartisan\"      \"bird\"            \"birth\"           \"birther\"        \n",
      " [221] \"birthright\"      \"bishop\"          \"bite\"            \"black\"          \n",
      " [225] \"blame\"           \"blind\"           \"block\"           \"blow\"           \n",
      " [229] \"blue\"            \"blunt\"           \"board\"           \"bob\"            \n",
      " [233] \"bodi\"            \"bomb\"            \"bomber\"          \"bond\"           \n",
      " [237] \"bonus\"           \"book\"            \"boost\"           \"boot\"           \n",
      " [241] \"border\"          \"borrow\"          \"bottom\"          \"bowl\"           \n",
      " [245] \"boxer\"           \"boy\"             \"brad\"            \"brag\"           \n",
      " [249] \"branch\"          \"brand\"           \"brat\"            \"brave\"          \n",
      " [253] \"break\"           \"bridg\"           \"bring\"           \"brother\"        \n",
      " [257] \"brotherhood\"     \"brown\"           \"buck\"            \"budg\"           \n",
      " [261] \"budget\"          \"build\"           \"bulb\"            \"bulk\"           \n",
      " [265] \"bullet\"          \"bunch\"           \"burden\"          \"bureau\"         \n",
      " [269] \"bureaucrat\"      \"burn\"            \"burr\"            \"bus\"            \n",
      " [273] \"bush\"            \"busi\"            \"buy\"             \"cabinet\"        \n",
      " [277] \"call\"            \"camera\"          \"camp\"            \"campaign\"       \n",
      " [281] \"campus\"          \"can\"             \"cancel\"          \"cancer\"         \n",
      " [285] \"candid\"          \"candidaci\"       \"cannon\"          \"cant\"           \n",
      " [289] \"cantor\"          \"cap\"             \"capabl\"          \"capit\"          \n",
      " [293] \"capitol\"         \"captur\"          \"car\"             \"carbon\"         \n",
      " [297] \"card\"            \"care\"            \"career\"          \"carri\"          \n",
      " [301] \"carrier\"         \"cartel\"          \"carter\"          \"case\"           \n",
      " [305] \"cash\"            \"casino\"          \"cast\"            \"casualti\"       \n",
      " [309] \"cat\"             \"catch\"           \"cathol\"          \"caucus\"         \n",
      " [313] \"caus\"            \"ceil\"            \"celebr\"          \"cell\"           \n",
      " [317] \"census\"          \"cent\"            \"center\"          \"central\"        \n",
      " [321] \"centuri\"         \"certain\"         \"chair\"           \"chairman\"       \n",
      " [325] \"challeng\"        \"chamber\"         \"champion\"        \"championship\"   \n",
      " [329] \"chanc\"           \"chang\"           \"charg\"           \"charit\"         \n",
      " [333] \"chariti\"         \"charli\"          \"charter\"         \"cheap\"          \n",
      " [337] \"cheat\"           \"check\"           \"chees\"           \"chemic\"         \n",
      " [341] \"chicken\"         \"chief\"           \"child\"           \"childhood\"      \n",
      " [345] \"china\"           \"choic\"           \"choos\"           \"christian\"      \n",
      " [349] \"chuck\"           \"church\"          \"cigarett\"        \"circuit\"        \n",
      " [353] \"circumst\"        \"citat\"           \"cite\"            \"citi\"           \n",
      " [357] \"citizen\"         \"citizenship\"     \"civil\"           \"civilian\"       \n",
      " [361] \"claim\"           \"class\"           \"classifi\"        \"classroom\"      \n",
      " [365] \"clean\"           \"cleanup\"         \"clear\"           \"clerk\"          \n",
      " [369] \"cliff\"           \"climat\"          \"climb\"           \"clinic\"         \n",
      " [373] \"clip\"            \"close\"           \"cloth\"           \"club\"           \n",
      " [377] \"clunker\"         \"coach\"           \"coal\"            \"coalit\"         \n",
      " [381] \"coast\"           \"code\"            \"cold\"            \"collaps\"        \n",
      " [385] \"colleagu\"        \"collect\"         \"colleg\"          \"color\"          \n",
      " [389] \"combat\"          \"combin\"          \"come\"            \"comment\"        \n",
      " [393] \"commerc\"         \"commerci\"        \"commiss\"         \"commission\"     \n",
      " [397] \"commit\"          \"committe\"        \"common\"          \"commonwealth\"   \n",
      " [401] \"communist\"       \"communiti\"       \"compact\"         \"compani\"        \n",
      " [405] \"compar\"          \"compens\"         \"competit\"        \"complet\"        \n",
      " [409] \"compli\"          \"comprehens\"      \"compris\"         \"compromis\"      \n",
      " [413] \"comput\"          \"conceal\"         \"concentr\"        \"concept\"        \n",
      " [417] \"concern\"         \"conclud\"         \"condemn\"         \"condit\"         \n",
      " [421] \"conduct\"         \"confirm\"         \"conflict\"        \"confront\"       \n",
      " [425] \"congress\"        \"congression\"     \"congressman\"     \"connect\"        \n",
      " [429] \"consecut\"        \"consent\"         \"consequ\"         \"conserv\"        \n",
      " [433] \"consid\"          \"consist\"         \"constant\"        \"constitu\"       \n",
      " [437] \"constitut\"       \"construct\"       \"consult\"         \"consum\"         \n",
      " [441] \"consumpt\"        \"contain\"         \"continu\"         \"contracept\"     \n",
      " [445] \"contract\"        \"contractor\"      \"contrari\"        \"contribut\"      \n",
      " [449] \"control\"         \"controversi\"     \"convent\"         \"convers\"        \n",
      " [453] \"convert\"         \"convict\"         \"cook\"            \"cop\"            \n",
      " [457] \"core\"            \"corn\"            \"corp\"            \"corpor\"         \n",
      " [461] \"correct\"         \"corridor\"        \"corrupt\"         \"cosponsor\"      \n",
      " [465] \"cost\"            \"cotton\"          \"council\"         \"counsel\"        \n",
      " [469] \"count\"           \"counterpart\"     \"counti\"          \"countri\"        \n",
      " [473] \"coupl\"           \"cours\"           \"court\"           \"cousin\"         \n",
      " [477] \"cover\"           \"coverag\"         \"cowboy\"          \"crack\"          \n",
      " [481] \"crackdown\"       \"crash\"           \"creat\"           \"creation\"       \n",
      " [485] \"credit\"          \"crime\"           \"crimin\"          \"crippl\"         \n",
      " [489] \"crisi\"           \"critic\"          \"crop\"            \"cross\"          \n",
      " [493] \"cup\"             \"cure\"            \"current\"         \"custom\"         \n",
      " [497] \"cut\"             \"czar\"            \"dad\"             \"daili\"          \n",
      " [501] \"damag\"           \"danger\"          \"databas\"         \"date\"           \n",
      " [505] \"datum\"           \"daughter\"        \"day\"             \"dc\"             \n",
      " [509] \"dead\"            \"deadlin\"         \"deal\"            \"dealer\"         \n",
      " [513] \"dean\"            \"death\"           \"debat\"           \"debt\"           \n",
      " [517] \"debunk\"          \"decad\"           \"decid\"           \"decis\"          \n",
      " [521] \"declar\"          \"declin\"          \"decor\"           \"decreas\"        \n",
      " [525] \"dedic\"           \"deduct\"          \"deem\"            \"deep\"           \n",
      " [529] \"deer\"            \"defeat\"          \"defend\"          \"defens\"         \n",
      " [533] \"deficit\"         \"defin\"           \"definit\"         \"degre\"          \n",
      " [537] \"delay\"           \"deleg\"           \"delet\"           \"deliv\"          \n",
      " [541] \"demand\"          \"democrat\"        \"deni\"            \"dental\"         \n",
      " [545] \"depart\"          \"depend\"          \"deploy\"          \"deport\"         \n",
      " [549] \"deposit\"         \"depress\"         \"depriv\"          \"deputi\"         \n",
      " [553] \"derail\"          \"deregul\"         \"describ\"         \"deserv\"         \n",
      " [557] \"design\"          \"desk\"            \"despit\"          \"destroy\"        \n",
      " [561] \"detail\"          \"detaine\"         \"determin\"        \"devast\"         \n",
      " [565] \"develop\"         \"devic\"           \"die\"             \"differ\"         \n",
      " [569] \"difficult\"       \"digit\"           \"dime\"            \"diploma\"        \n",
      " [573] \"direct\"          \"director\"        \"dirti\"           \"disabl\"         \n",
      " [577] \"disagre\"         \"disappear\"       \"disast\"          \"disastr\"        \n",
      " [581] \"discharg\"        \"disclos\"         \"disclosur\"       \"discov\"         \n",
      " [585] \"discret\"         \"discretionari\"   \"discrimin\"       \"discuss\"        \n",
      " [589] \"diseas\"          \"disgrac\"         \"disproportion\"   \"disput\"         \n",
      " [593] \"disrupt\"         \"distribut\"       \"district\"        \"divers\"         \n",
      " [597] \"divert\"          \"divis\"           \"divorc\"          \"do\"             \n",
      " [601] \"doctor\"          \"document\"        \"dog\"             \"dollar\"         \n",
      " [605] \"domain\"          \"dome\"            \"domest\"          \"domin\"          \n",
      " [609] \"donat\"           \"donor\"           \"door\"            \"dorm\"           \n",
      " [613] \"doubl\"           \"doubt\"           \"downgrad\"        \"downtown\"       \n",
      " [617] \"dozen\"           \"draft\"           \"drain\"           \"dramat\"         \n",
      " [621] \"draw\"            \"dream\"           \"dreamer\"         \"drill\"          \n",
      " [625] \"drink\"           \"drive\"           \"driver\"          \"drone\"          \n",
      " [629] \"drop\"            \"dropout\"         \"drug\"            \"duck\"           \n",
      " [633] \"due\"             \"dump\"            \"duti\"            \"earli\"          \n",
      " [637] \"earmark\"         \"earn\"            \"earner\"          \"earth\"          \n",
      " [641] \"eas\"             \"easi\"            \"east\"            \"eastern\"        \n",
      " [645] \"eat\"             \"econom\"          \"economi\"         \"economist\"      \n",
      " [649] \"ed\"              \"edit\"            \"educ\"            \"effect\"         \n",
      " [653] \"effici\"          \"effort\"          \"egg\"             \"eight\"          \n",
      " [657] \"eighti\"          \"either\"          \"elder\"           \"elect\"          \n",
      " [661] \"elector\"         \"electr\"          \"electron\"        \"elementari\"     \n",
      " [665] \"elig\"            \"elimin\"          \"els\"             \"elsewher\"       \n",
      " [669] \"email\"           \"embassi\"         \"embrac\"          \"embryon\"        \n",
      " [673] \"emerg\"           \"emin\"            \"emiss\"           \"employ\"         \n",
      " [677] \"employe\"         \"enact\"           \"encourag\"        \"end\"            \n",
      " [681] \"endors\"          \"enemi\"           \"energi\"          \"enforc\"         \n",
      " [685] \"engag\"           \"engin\"           \"enjoy\"           \"enorm\"          \n",
      " [689] \"enough\"          \"enrol\"           \"ensur\"           \"enter\"          \n",
      " [693] \"enterpris\"       \"entir\"           \"entitl\"          \"entri\"          \n",
      " [697] \"environ\"         \"environment\"     \"equal\"           \"equip\"          \n",
      " [701] \"equival\"         \"escap\"           \"especi\"          \"essenti\"        \n",
      " [705] \"establish\"       \"estat\"           \"estim\"           \"ethanol\"        \n",
      " [709] \"ethic\"           \"ethnic\"          \"even\"            \"event\"          \n",
      " [713] \"eventu\"          \"ever\"            \"everi\"           \"everybodi\"      \n",
      " [717] \"everyon\"         \"everyth\"         \"evid\"            \"evolut\"         \n",
      " [721] \"exact\"           \"exam\"            \"exampl\"          \"exceed\"         \n",
      " [725] \"except\"          \"exchang\"         \"exclud\"          \"exclus\"         \n",
      " [729] \"execut\"          \"exempt\"          \"exercis\"         \"exist\"          \n",
      " [733] \"exoner\"          \"expand\"          \"expans\"          \"expect\"         \n",
      " [737] \"expenditur\"      \"expens\"          \"experi\"          \"expert\"         \n",
      " [741] \"expir\"           \"explain\"         \"explicit\"        \"exploit\"        \n",
      " [745] \"explor\"          \"explos\"          \"export\"          \"express\"        \n",
      " [749] \"extend\"          \"extens\"          \"extra\"           \"extrem\"         \n",
      " [753] \"extremist\"       \"eye\"             \"f\"               \"face\"           \n",
      " [757] \"facil\"           \"fact\"            \"factor\"          \"factori\"        \n",
      " [761] \"faculti\"         \"fail\"            \"failur\"          \"fair\"           \n",
      " [765] \"faith\"           \"fall\"            \"fals\"            \"famili\"         \n",
      " [769] \"fanci\"           \"far\"             \"farm\"            \"farmer\"         \n",
      " [773] \"fast\"            \"fatal\"           \"father\"          \"favor\"          \n",
      " [777] \"favorit\"         \"fear\"            \"featur\"          \"feder\"          \n",
      " [781] \"fee\"             \"feed\"            \"feel\"            \"fellow\"         \n",
      " [785] \"felon\"           \"feloni\"          \"femal\"           \"fenc\"           \n",
      " [789] \"few\"             \"field\"           \"fifti\"           \"fight\"          \n",
      " [793] \"fighter\"         \"figur\"           \"file\"            \"filibust\"       \n",
      " [797] \"fill\"            \"film\"            \"final\"           \"financ\"         \n",
      " [801] \"financi\"         \"find\"            \"fine\"            \"finish\"         \n",
      " [805] \"fire\"            \"firearm\"         \"firefight\"       \"firm\"           \n",
      " [809] \"first\"           \"fiscal\"          \"fish\"            \"five\"           \n",
      " [813] \"fix\"             \"fl\"              \"flag\"            \"flat\"           \n",
      " [817] \"flaw\"            \"flee\"            \"fleet\"           \"fli\"            \n",
      " [821] \"flight\"          \"flood\"           \"floor\"           \"flow\"           \n",
      " [825] \"flu\"             \"fluorid\"         \"focus\"           \"folk\"           \n",
      " [829] \"follow\"          \"food\"            \"foot\"            \"footbal\"        \n",
      " [833] \"forc\"            \"foreclosur\"      \"foreign\"         \"form\"           \n",
      " [837] \"former\"          \"fort\"            \"forti\"           \"fortun\"         \n",
      " [841] \"forward\"         \"found\"           \"foundat\"         \"founder\"        \n",
      " [845] \"four\"            \"fox\"             \"frack\"           \"frank\"          \n",
      " [849] \"fraud\"           \"free\"            \"freedom\"         \"freeway\"        \n",
      " [853] \"freez\"           \"frequent\"        \"fresh\"           \"freshman\"       \n",
      " [857] \"friend\"          \"front\"           \"fuel\"            \"full\"           \n",
      " [861] \"fulli\"           \"function\"        \"fund\"            \"fundrais\"       \n",
      " [865] \"funnel\"          \"futur\"           \"gain\"            \"gallon\"         \n",
      " [869] \"gambl\"           \"game\"            \"gang\"            \"gap\"            \n",
      " [873] \"gas\"             \"gasolin\"         \"gather\"          \"gay\"            \n",
      " [877] \"gen\"             \"gender\"          \"general\"         \"generat\"        \n",
      " [881] \"generous\"        \"genet\"           \"genocid\"         \"geograph\"       \n",
      " [885] \"get\"             \"gift\"            \"girl\"            \"give\"           \n",
      " [889] \"global\"          \"gm\"              \"go\"              \"goal\"           \n",
      " [893] \"god\"             \"gold\"            \"golf\"            \"good\"           \n",
      " [897] \"googl\"           \"gore\"            \"gov\"             \"govern\"         \n",
      " [901] \"governor\"        \"grab\"            \"grade\"           \"graduat\"        \n",
      " [905] \"grand\"           \"granit\"          \"grant\"           \"great\"          \n",
      " [909] \"green\"           \"greenhous\"       \"grind\"           \"groceri\"        \n",
      " [913] \"gross\"           \"group\"           \"grow\"            \"growth\"         \n",
      " [917] \"guarante\"        \"guard\"           \"gubernatori\"     \"guess\"          \n",
      " [921] \"guilti\"          \"gulf\"            \"gun\"             \"gunfir\"         \n",
      " [925] \"gut\"             \"guy\"             \"habit\"           \"half\"           \n",
      " [929] \"halfway\"         \"hall\"            \"ham\"             \"hammer\"         \n",
      " [933] \"hand\"            \"handgun\"         \"happen\"          \"happi\"          \n",
      " [937] \"harass\"          \"hard\"            \"harm\"            \"harri\"          \n",
      " [941] \"hate\"            \"have\"            \"head\"            \"headquart\"      \n",
      " [945] \"health\"          \"healthcar\"       \"healthi\"         \"hear\"           \n",
      " [949] \"heart\"           \"heavi\"           \"heavili\"         \"heck\"           \n",
      " [953] \"helicopt\"        \"hell\"            \"help\"            \"heroin\"         \n",
      " [957] \"hes\"             \"hide\"            \"high\"            \"highway\"        \n",
      " [961] \"hike\"            \"hill\"            \"hire\"            \"histor\"         \n",
      " [965] \"histori\"         \"hit\"             \"hold\"            \"holder\"         \n",
      " [969] \"hole\"            \"holiday\"         \"home\"            \"homeland\"       \n",
      " [973] \"homeless\"        \"homeown\"         \"homicid\"         \"homosexu\"       \n",
      " [977] \"honor\"           \"hood\"            \"hook\"            \"hope\"           \n",
      " [981] \"hors\"            \"hospit\"          \"host\"            \"hostag\"         \n",
      " [985] \"hotel\"           \"hour\"            \"hous\"            \"household\"      \n",
      " [989] \"huge\"            \"human\"           \"hundr\"           \"hunt\"           \n",
      " [993] \"hurrican\"        \"hurt\"            \"husband\"         \"ice\"            \n",
      " [997] \"id\"              \"idea\"            \"ident\"           \"identif\"        \n",
      "[1001] \"identifi\"        \"ii\"              \"ill\"             \"illeg\"          \n",
      "[1005] \"imag\"            \"immedi\"          \"immigr\"          \"immun\"          \n",
      "[1009] \"impact\"          \"impeach\"         \"implement\"       \"import\"         \n",
      "[1013] \"impos\"           \"imposs\"          \"imprison\"        \"improv\"         \n",
      "[1017] \"inact\"           \"incarcer\"        \"incent\"          \"incest\"         \n",
      "[1021] \"inch\"            \"incid\"           \"includ\"          \"incom\"          \n",
      "[1025] \"increas\"         \"incumb\"          \"independ\"        \"indic\"          \n",
      "[1029] \"individu\"        \"industri\"        \"ineffect\"        \"inequ\"          \n",
      "[1033] \"infant\"          \"infect\"          \"inflat\"          \"influenc\"       \n",
      "[1037] \"inform\"          \"infrastructur\"   \"inherit\"         \"initi\"          \n",
      "[1041] \"injuri\"          \"inmat\"           \"insid\"           \"inspect\"        \n",
      "[1045] \"inspir\"          \"instal\"          \"instanc\"         \"instat\"         \n",
      "[1049] \"instead\"         \"institut\"        \"instruct\"        \"insur\"          \n",
      "[1053] \"intellig\"        \"intend\"          \"intent\"          \"interest\"       \n",
      "[1057] \"interior\"        \"intern\"          \"internet\"        \"interview\"      \n",
      "[1061] \"introduc\"        \"invad\"           \"invas\"           \"invent\"         \n",
      "[1065] \"invest\"          \"investig\"        \"investor\"        \"invit\"          \n",
      "[1069] \"involv\"          \"iron\"            \"island\"          \"issu\"           \n",
      "[1073] \"item\"            \"jack\"            \"jail\"            \"japan\"          \n",
      "[1077] \"jeopard\"         \"jersey\"          \"jet\"             \"jimmi\"          \n",
      "[1081] \"job\"             \"jobless\"         \"john\"            \"johnni\"         \n",
      "[1085] \"join\"            \"joke\"            \"jolli\"           \"josh\"           \n",
      "[1089] \"jr\"              \"judg\"            \"judgment\"        \"judici\"         \n",
      "[1093] \"jump\"            \"junket\"          \"just\"            \"justic\"         \n",
      "[1097] \"justifi\"         \"keep\"            \"ken\"             \"key\"            \n",
      "[1101] \"keyston\"         \"kick\"            \"kicker\"          \"kid\"            \n",
      "[1105] \"kidnap\"          \"kill\"            \"killer\"          \"kind\"           \n",
      "[1109] \"kindergarten\"    \"king\"            \"know\"            \"knowledg\"       \n",
      "[1113] \"lab\"             \"label\"           \"labor\"           \"lack\"           \n",
      "[1117] \"lade\"            \"ladi\"            \"lake\"            \"land\"           \n",
      "[1121] \"lane\"            \"languag\"         \"larg\"            \"last\"           \n",
      "[1125] \"late\"            \"launch\"          \"law\"             \"lawmak\"         \n",
      "[1129] \"lawsuit\"         \"lawyer\"          \"lay\"             \"layoff\"         \n",
      "[1133] \"lead\"            \"leader\"          \"leadership\"      \"leagu\"          \n",
      "[1137] \"learn\"           \"leas\"            \"leav\"            \"lee\"            \n",
      "[1141] \"legal\"           \"legisl\"          \"legislatur\"      \"legitim\"        \n",
      "[1145] \"lend\"            \"lender\"          \"lesbian\"         \"less\"           \n",
      "[1149] \"let\"             \"letter\"          \"level\"           \"levi\"           \n",
      "[1153] \"liabil\"          \"liber\"           \"liberti\"         \"librari\"        \n",
      "[1157] \"licens\"          \"lie\"             \"lieuten\"         \"life\"           \n",
      "[1161] \"lifetim\"         \"lift\"            \"light\"           \"like\"           \n",
      "[1165] \"limit\"           \"line\"            \"link\"            \"liquor\"         \n",
      "[1169] \"list\"            \"liter\"           \"littl\"           \"live\"           \n",
      "[1173] \"load\"            \"loan\"            \"lobbi\"           \"lobbyist\"       \n",
      "[1177] \"local\"           \"locat\"           \"lock\"            \"log\"            \n",
      "[1181] \"long\"            \"longstand\"       \"look\"            \"loophol\"        \n",
      "[1185] \"lose\"            \"loss\"            \"lot\"             \"lotteri\"        \n",
      "[1189] \"loud\"            \"love\"            \"low\"             \"lower\"          \n",
      "[1193] \"lunch\"           \"luxuri\"          \"lynch\"           \"mac\"            \n",
      "[1197] \"machin\"          \"magazin\"         \"mail\"            \"main\"           \n",
      "[1201] \"major\"           \"make\"            \"makeup\"          \"male\"           \n",
      "[1205] \"mammogram\"       \"man\"             \"manag\"           \"mandat\"         \n",
      "[1209] \"mandatori\"       \"mani\"            \"manipul\"         \"mansion\"        \n",
      "[1213] \"manufactur\"      \"march\"           \"margin\"          \"marijuana\"      \n",
      "[1217] \"marin\"           \"mark\"            \"market\"          \"marketplac\"     \n",
      "[1221] \"marri\"           \"marriag\"         \"martin\"          \"mass\"           \n",
      "[1225] \"massiv\"          \"match\"           \"mate\"            \"matern\"         \n",
      "[1229] \"math\"            \"mathemat\"        \"matter\"          \"max\"            \n",
      "[1233] \"may\"             \"mayb\"            \"mayor\"           \"meal\"           \n",
      "[1237] \"mean\"            \"measl\"           \"measur\"          \"meat\"           \n",
      "[1241] \"mechan\"          \"medal\"           \"median\"          \"medic\"          \n",
      "[1245] \"medicaid\"        \"medicar\"         \"medicin\"         \"medium\"         \n",
      "[1249] \"meek\"            \"meet\"            \"meltdown\"        \"member\"         \n",
      "[1253] \"memori\"          \"mental\"          \"mention\"         \"mercuri\"        \n",
      "[1257] \"merger\"          \"merit\"           \"mess\"            \"method\"         \n",
      "[1261] \"metro\"           \"metropolitan\"    \"mid\"             \"middl\"          \n",
      "[1265] \"midnight\"        \"midterm\"         \"mike\"            \"mile\"           \n",
      "[1269] \"militari\"        \"milk\"            \"mill\"            \"million\"        \n",
      "[1273] \"millionair\"      \"mind\"            \"mine\"            \"minim\"          \n",
      "[1277] \"minimum\"         \"minist\"          \"minor\"           \"minut\"          \n",
      "[1281] \"mirror\"          \"mismanag\"        \"miss\"            \"missil\"         \n",
      "[1285] \"mission\"         \"mistak\"          \"mitt\"            \"mo\"             \n",
      "[1289] \"model\"           \"moder\"           \"modern\"          \"modifi\"         \n",
      "[1293] \"mom\"             \"moment\"          \"money\"           \"month\"          \n",
      "[1297] \"moratorium\"      \"morn\"            \"mortal\"          \"mortgag\"        \n",
      "[1301] \"mosqu\"           \"most\"            \"mother\"          \"motor\"          \n",
      "[1305] \"motorist\"        \"move\"            \"movement\"        \"movi\"           \n",
      "[1309] \"mph\"             \"much\"            \"multipl\"         \"municip\"        \n",
      "[1313] \"murder\"          \"museum\"          \"must\"            \"name\"           \n",
      "[1317] \"nation\"          \"nationwid\"       \"natur\"           \"navi\"           \n",
      "[1321] \"navig\"           \"nd\"              \"near\"            \"need\"           \n",
      "[1325] \"needi\"           \"negat\"           \"negoti\"          \"neighbor\"       \n",
      "[1329] \"neighborhood\"    \"neither\"         \"nelson\"          \"net\"            \n",
      "[1333] \"network\"         \"neutral\"         \"never\"           \"new\"            \n",
      "[1337] \"newborn\"         \"newli\"           \"news\"            \"newspap\"        \n",
      "[1341] \"newt\"            \"next\"            \"nickel\"          \"night\"          \n",
      "[1345] \"nine\"            \"nineti\"          \"nobodi\"          \"nomin\"          \n",
      "[1349] \"nomine\"          \"none\"            \"nonpartisan\"     \"nonprofit\"      \n",
      "[1353] \"north\"           \"northern\"        \"note\"            \"noth\"           \n",
      "[1357] \"now\"             \"nowher\"          \"nuclear\"         \"numb\"           \n",
      "[1361] \"number\"          \"numer\"           \"nurs\"            \"obes\"           \n",
      "[1365] \"object\"          \"obsolet\"         \"obtain\"          \"occupi\"         \n",
      "[1369] \"occur\"           \"ocean\"           \"odd\"             \"offend\"         \n",
      "[1373] \"offens\"          \"offer\"           \"offic\"           \"offici\"         \n",
      "[1377] \"offset\"          \"offshor\"         \"often\"           \"oil\"            \n",
      "[1381] \"old\"             \"omnibus\"         \"one\"             \"onlin\"          \n",
      "[1385] \"onto\"            \"open\"            \"oper\"            \"opinion\"        \n",
      "[1389] \"oppon\"           \"opportun\"        \"oppos\"           \"opposit\"        \n",
      "[1393] \"opt\"             \"option\"          \"order\"           \"ordin\"          \n",
      "[1397] \"ordinari\"        \"ore\"             \"organ\"           \"orient\"         \n",
      "[1401] \"origin\"          \"other\"           \"otherwis\"        \"outlaw\"         \n",
      "[1405] \"output\"          \"outrag\"          \"outsid\"          \"outsourc\"       \n",
      "[1409] \"outstrip\"        \"overal\"          \"overdos\"         \"overhaul\"       \n",
      "[1413] \"overhead\"        \"overse\"          \"oversea\"         \"oversight\"      \n",
      "[1417] \"overstay\"        \"overturn\"        \"overwhelm\"       \"owe\"            \n",
      "[1421] \"own\"             \"owner\"           \"ownership\"       \"pace\"           \n",
      "[1425] \"packag\"          \"page\"            \"pain\"            \"paint\"          \n",
      "[1429] \"panel\"           \"panhandl\"        \"pant\"            \"panther\"        \n",
      "[1433] \"paper\"           \"paperwork\"       \"parent\"          \"parenthood\"     \n",
      "[1437] \"park\"            \"part\"            \"parti\"           \"partial\"        \n",
      "[1441] \"particip\"        \"particular\"      \"partisan\"        \"partner\"        \n",
      "[1445] \"partnership\"     \"pass\"            \"passag\"          \"past\"           \n",
      "[1449] \"pastor\"          \"pat\"             \"path\"            \"patient\"        \n",
      "[1453] \"patriot\"         \"patrol\"          \"pay\"             \"paycheck\"       \n",
      "[1457] \"payday\"          \"payment\"         \"payrol\"          \"peak\"           \n",
      "[1461] \"peanut\"          \"penalti\"         \"pend\"            \"penni\"          \n",
      "[1465] \"pension\"         \"pentagon\"        \"peopl\"           \"per\"            \n",
      "[1469] \"percent\"         \"percentag\"       \"perfect\"         \"perform\"        \n",
      "[1473] \"perhap\"          \"period\"          \"perman\"          \"permit\"         \n",
      "[1477] \"person\"          \"personnel\"       \"peter\"           \"petit\"          \n",
      "[1481] \"petroleum\"       \"pharmaceut\"      \"phoenix\"         \"phone\"          \n",
      "[1485] \"photo\"           \"photograph\"      \"physic\"          \"physician\"      \n",
      "[1489] \"pick\"            \"pictur\"          \"piec\"            \"pink\"           \n",
      "[1493] \"pipelin\"         \"pizza\"           \"place\"           \"plan\"           \n",
      "[1497] \"plane\"           \"planet\"          \"plant\"           \"platform\"       \n",
      "[1501] \"play\"            \"player\"          \"pledg\"           \"plot\"           \n",
      "[1505] \"plus\"            \"pm\"              \"pocket\"          \"point\"          \n",
      "[1509] \"poison\"          \"polic\"           \"policeman\"       \"polici\"         \n",
      "[1513] \"polit\"           \"politician\"      \"poll\"            \"pollut\"         \n",
      "[1517] \"poni\"            \"poor\"            \"pop\"             \"popul\"          \n",
      "[1521] \"popular\"         \"pork\"            \"port\"            \"portion\"        \n",
      "[1525] \"pose\"            \"posit\"           \"possess\"         \"possibl\"        \n",
      "[1529] \"post\"            \"postal\"          \"pot\"             \"potenti\"        \n",
      "[1533] \"poverti\"         \"power\"           \"practic\"         \"prais\"          \n",
      "[1537] \"pray\"            \"prayer\"          \"preced\"          \"precinct\"       \n",
      "[1541] \"predat\"          \"predecessor\"     \"predict\"         \"preexist\"       \n",
      "[1545] \"prefer\"          \"pregnanc\"        \"pregnant\"        \"prekindergarten\"\n",
      "[1549] \"prematur\"        \"premium\"         \"prepar\"          \"preschool\"      \n",
      "[1553] \"prescript\"       \"presenc\"         \"present\"         \"presid\"         \n",
      "[1557] \"presidenti\"      \"press\"           \"pressur\"         \"pretti\"         \n",
      "[1561] \"prevent\"         \"previous\"        \"price\"           \"primari\"        \n",
      "[1565] \"prime\"           \"princip\"         \"print\"           \"prior\"          \n",
      "[1569] \"prioriti\"        \"prison\"          \"pristin\"         \"privat\"         \n",
      "[1573] \"privileg\"        \"probabl\"         \"probe\"           \"problem\"        \n",
      "[1577] \"procedur\"        \"process\"         \"produc\"          \"product\"        \n",
      "[1581] \"profession\"      \"profici\"         \"profit\"          \"program\"        \n",
      "[1585] \"progress\"        \"prohibit\"        \"project\"         \"promis\"         \n",
      "[1589] \"promot\"          \"prompt\"          \"proof\"           \"proper\"         \n",
      "[1593] \"properti\"        \"proport\"         \"propos\"          \"proposit\"       \n",
      "[1597] \"prosecut\"        \"prosecutor\"      \"prosper\"         \"prostitut\"      \n",
      "[1601] \"protect\"         \"protest\"         \"proud\"           \"prove\"          \n",
      "[1605] \"provid\"          \"provis\"          \"provision\"       \"public\"         \n",
      "[1609] \"pull\"            \"pump\"            \"pupil\"           \"purchas\"        \n",
      "[1613] \"purg\"            \"purpos\"          \"pursu\"           \"push\"           \n",
      "[1617] \"put\"             \"quadrupl\"        \"qualifi\"         \"qualiti\"        \n",
      "[1621] \"quarter\"         \"question\"        \"quick\"           \"quiet\"          \n",
      "[1625] \"quit\"            \"quot\"            \"race\"            \"racial\"         \n",
      "[1629] \"rack\"            \"radic\"           \"radio\"           \"raid\"           \n",
      "[1633] \"rail\"            \"raini\"           \"rais\"            \"rake\"           \n",
      "[1637] \"ralli\"           \"rand\"            \"rang\"            \"rank\"           \n",
      "[1641] \"rape\"            \"rare\"            \"rate\"            \"rather\"         \n",
      "[1645] \"ratio\"           \"rd\"              \"reach\"           \"read\"           \n",
      "[1649] \"readi\"           \"real\"            \"realiti\"         \"realli\"         \n",
      "[1653] \"reason\"          \"rebat\"           \"rebel\"           \"rebuild\"        \n",
      "[1657] \"recal\"           \"receiv\"          \"recent\"          \"recess\"         \n",
      "[1661] \"recidiv\"         \"recipi\"          \"recogn\"          \"recommend\"      \n",
      "[1665] \"reconcili\"       \"record\"          \"recount\"         \"recov\"          \n",
      "[1669] \"recoveri\"        \"recreat\"         \"recruit\"         \"red\"            \n",
      "[1673] \"redistrict\"      \"redskin\"         \"reduc\"           \"reduct\"         \n",
      "[1677] \"reed\"            \"reelect\"         \"refer\"           \"referendum\"     \n",
      "[1681] \"refin\"           \"reform\"          \"refuge\"          \"refund\"         \n",
      "[1685] \"refus\"           \"regard\"          \"regardless\"      \"regim\"          \n",
      "[1689] \"region\"          \"regist\"          \"registr\"         \"regul\"          \n",
      "[1693] \"regular\"         \"regulatori\"      \"reimburs\"        \"rein\"           \n",
      "[1697] \"reinstat\"        \"reject\"          \"relat\"           \"relationship\"   \n",
      "[1701] \"releas\"          \"reli\"            \"relief\"          \"religi\"         \n",
      "[1705] \"religion\"        \"reloc\"           \"remain\"          \"remark\"         \n",
      "[1709] \"rememb\"          \"remodel\"         \"remov\"           \"rend\"           \n",
      "[1713] \"renew\"           \"rep\"             \"repair\"          \"repay\"          \n",
      "[1717] \"repeal\"          \"repeat\"          \"replac\"          \"report\"         \n",
      "[1721] \"repres\"          \"represent\"       \"reproduct\"       \"republ\"         \n",
      "[1725] \"republican\"      \"request\"         \"requir\"          \"rescu\"          \n",
      "[1729] \"research\"        \"reserv\"          \"resid\"           \"resign\"         \n",
      "[1733] \"resourc\"         \"respect\"         \"respond\"         \"respons\"        \n",
      "[1737] \"rest\"            \"restaur\"         \"restor\"          \"restrict\"       \n",
      "[1741] \"result\"          \"retain\"          \"retir\"           \"retire\"         \n",
      "[1745] \"return\"          \"rev\"             \"reveal\"          \"revenu\"         \n",
      "[1749] \"revers\"          \"review\"          \"revok\"           \"revolut\"        \n",
      "[1753] \"reward\"          \"rich\"            \"rick\"            \"rid\"            \n",
      "[1757] \"ride\"            \"rifl\"            \"rig\"             \"right\"          \n",
      "[1761] \"rise\"            \"risk\"            \"riski\"           \"rival\"          \n",
      "[1765] \"river\"           \"road\"            \"rob\"             \"robberi\"        \n",
      "[1769] \"roe\"             \"role\"            \"roll\"            \"room\"           \n",
      "[1773] \"rough\"           \"round\"           \"routin\"          \"row\"            \n",
      "[1777] \"royalti\"         \"rug\"             \"rule\"            \"run\"            \n",
      "[1781] \"rural\"           \"rush\"            \"sacrific\"        \"safe\"           \n",
      "[1785] \"safeti\"          \"salari\"          \"sale\"            \"sanction\"       \n",
      "[1789] \"sanctuari\"       \"sander\"          \"sandi\"           \"sandwich\"       \n",
      "[1793] \"save\"            \"say\"             \"scandal\"         \"schedul\"        \n",
      "[1797] \"scheme\"          \"scholarship\"     \"school\"          \"schoolchild\"    \n",
      "[1801] \"scienc\"          \"scientif\"        \"scientist\"       \"score\"          \n",
      "[1805] \"screen\"          \"search\"          \"seat\"            \"seced\"          \n",
      "[1809] \"second\"          \"secret\"          \"secretari\"       \"sector\"         \n",
      "[1813] \"secur\"           \"see\"             \"seek\"            \"seem\"           \n",
      "[1817] \"seiz\"            \"select\"          \"sell\"            \"sen\"            \n",
      "[1821] \"senat\"           \"send\"            \"senior\"          \"sens\"           \n",
      "[1825] \"sentenc\"         \"separ\"           \"sequest\"         \"sequestr\"       \n",
      "[1829] \"seri\"            \"serious\"         \"serv\"            \"servic\"         \n",
      "[1833] \"session\"         \"set\"             \"seven\"           \"seventi\"        \n",
      "[1837] \"sever\"           \"sex\"             \"sexual\"          \"share\"          \n",
      "[1841] \"sharia\"          \"shell\"           \"shelter\"         \"sheriff\"        \n",
      "[1845] \"shes\"            \"shift\"           \"ship\"            \"shoot\"          \n",
      "[1849] \"shooter\"         \"shop\"            \"shore\"           \"short\"          \n",
      "[1853] \"shortfal\"        \"show\"            \"shower\"          \"shrink\"         \n",
      "[1857] \"shut\"            \"shutdown\"        \"sic\"             \"sick\"           \n",
      "[1861] \"side\"            \"sign\"            \"signatur\"        \"signific\"       \n",
      "[1865] \"similar\"         \"simpl\"           \"simpli\"          \"sinc\"           \n",
      "[1869] \"singl\"           \"sink\"            \"sit\"             \"site\"           \n",
      "[1873] \"situat\"          \"six\"             \"sixti\"           \"size\"           \n",
      "[1877] \"skill\"           \"skip\"            \"skyrocket\"       \"slash\"          \n",
      "[1881] \"slave\"           \"slaveri\"         \"slow\"            \"slush\"          \n",
      "[1885] \"small\"           \"smart\"           \"smoke\"           \"smoker\"         \n",
      "[1889] \"soar\"            \"soccer\"          \"social\"          \"socialist\"      \n",
      "[1893] \"societi\"         \"solar\"           \"soldier\"         \"solitari\"       \n",
      "[1897] \"solut\"           \"solv\"            \"somebodi\"        \"somehow\"        \n",
      "[1901] \"someon\"          \"someth\"          \"sometim\"         \"somewher\"       \n",
      "[1905] \"son\"             \"sonogram\"        \"soon\"            \"sort\"           \n",
      "[1909] \"sound\"           \"sourc\"           \"south\"           \"southeast\"      \n",
      "[1913] \"southern\"        \"southwest\"       \"soviet\"          \"space\"          \n",
      "[1917] \"speak\"           \"speaker\"         \"special\"         \"specif\"         \n",
      "[1921] \"speech\"          \"spend\"           \"spike\"           \"spill\"          \n",
      "[1925] \"spiral\"          \"spokesman\"       \"sponsor\"         \"sport\"          \n",
      "[1929] \"spot\"            \"spous\"           \"spread\"          \"spree\"          \n",
      "[1933] \"spring\"          \"squar\"           \"st\"              \"stabil\"         \n",
      "[1937] \"stadium\"         \"staff\"           \"staffer\"         \"stage\"          \n",
      "[1941] \"stamp\"           \"stand\"           \"standard\"        \"star\"           \n",
      "[1945] \"start\"           \"state\"           \"statement\"       \"statewid\"       \n",
      "[1949] \"station\"         \"statist\"         \"status\"          \"staunch\"        \n",
      "[1953] \"stay\"            \"steadili\"        \"steal\"           \"steel\"          \n",
      "[1957] \"stem\"            \"step\"            \"still\"           \"stimulus\"       \n",
      "[1961] \"stock\"           \"stone\"           \"stop\"            \"store\"          \n",
      "[1965] \"stori\"           \"straight\"        \"strateg\"         \"stream\"         \n",
      "[1969] \"street\"          \"streetcar\"       \"strict\"          \"strike\"         \n",
      "[1973] \"strip\"           \"strong\"          \"structur\"        \"student\"        \n",
      "[1977] \"studi\"           \"studio\"          \"stuff\"           \"subject\"        \n",
      "[1981] \"submit\"          \"subpoena\"        \"subprim\"         \"subsid\"         \n",
      "[1985] \"subsidi\"         \"substanc\"        \"substanti\"       \"substitut\"      \n",
      "[1989] \"succeed\"         \"success\"         \"sudden\"          \"sue\"            \n",
      "[1993] \"suffer\"          \"suggest\"         \"suicid\"          \"suit\"           \n",
      "[1997] \"summer\"          \"super\"           \"superintend\"     \"superior\"       \n",
      "[2001] \"supervisor\"      \"supplement\"      \"suppli\"          \"support\"        \n",
      "[2005] \"suppos\"          \"suprem\"          \"sure\"            \"surfac\"         \n",
      "[2009] \"surg\"            \"surgeri\"         \"surpass\"         \"surplus\"        \n",
      "[2013] \"surpris\"         \"surround\"        \"survey\"          \"surviv\"         \n",
      "[2017] \"suspect\"         \"suspend\"         \"swap\"            \"switch\"         \n",
      "[2021] \"syndrom\"         \"system\"          \"tabl\"            \"take\"           \n",
      "[2025] \"takeov\"          \"talk\"            \"tank\"            \"tap\"            \n",
      "[2029] \"tape\"            \"target\"          \"tarp\"            \"tattoo\"         \n",
      "[2033] \"tax\"             \"taxpay\"          \"tea\"             \"teach\"          \n",
      "[2037] \"teacher\"         \"team\"            \"tech\"            \"technic\"        \n",
      "[2041] \"technolog\"       \"ted\"             \"teddi\"           \"teen\"           \n",
      "[2045] \"teenag\"          \"televis\"         \"tell\"            \"temperatur\"     \n",
      "[2049] \"ten\"             \"tent\"            \"tenur\"           \"term\"           \n",
      "[2053] \"termin\"          \"terri\"           \"terribl\"         \"terror\"         \n",
      "[2057] \"terrorist\"       \"test\"            \"testifi\"         \"text\"           \n",
      "[2061] \"textbook\"        \"th\"              \"thank\"           \"theft\"          \n",
      "[2065] \"thing\"           \"think\"           \"third\"           \"though\"         \n",
      "[2069] \"thousand\"        \"threat\"          \"threaten\"        \"three\"          \n",
      "[2073] \"throughout\"      \"throw\"           \"ticket\"          \"tie\"            \n",
      "[2077] \"till\"            \"time\"            \"tobacco\"         \"today\"          \n",
      "[2081] \"togeth\"          \"toilet\"          \"toll\"            \"tom\"            \n",
      "[2085] \"tonight\"         \"top\"             \"tortur\"          \"total\"          \n",
      "[2089] \"touch\"           \"tough\"           \"toughen\"         \"tour\"           \n",
      "[2093] \"tourism\"         \"tout\"            \"toward\"          \"town\"           \n",
      "[2097] \"toxic\"           \"trace\"           \"track\"           \"trade\"          \n",
      "[2101] \"tradit\"          \"traffic\"         \"trail\"           \"train\"          \n",
      "[2105] \"transact\"        \"transfer\"        \"transgend\"       \"transit\"        \n",
      "[2109] \"translat\"        \"transpacif\"      \"transpar\"        \"transport\"      \n",
      "[2113] \"traumat\"         \"travel\"          \"treasur\"         \"treasuri\"       \n",
      "[2117] \"treat\"           \"treati\"          \"treatment\"       \"tree\"           \n",
      "[2121] \"tremend\"         \"trend\"           \"tri\"             \"trial\"          \n",
      "[2125] \"tribe\"           \"trigger\"         \"trillion\"        \"trip\"           \n",
      "[2129] \"tripl\"           \"troop\"           \"troubl\"          \"truck\"          \n",
      "[2133] \"true\"            \"trump\"           \"trust\"           \"truth\"          \n",
      "[2137] \"tuition\"         \"turbin\"          \"turn\"            \"turnout\"        \n",
      "[2141] \"turnpik\"         \"tweet\"           \"twenti\"          \"twice\"          \n",
      "[2145] \"twitter\"         \"two\"             \"type\"            \"typic\"          \n",
      "[2149] \"ultim\"           \"ultrasound\"      \"unaccount\"       \"unconstitut\"    \n",
      "[2153] \"undergo\"         \"understand\"      \"undocu\"          \"unemploy\"       \n",
      "[2157] \"unfair\"          \"unfund\"          \"uniform\"         \"unilater\"       \n",
      "[2161] \"uninsur\"         \"union\"           \"unit\"            \"univers\"        \n",
      "[2165] \"unlaw\"           \"unless\"          \"unlik\"           \"unlimit\"        \n",
      "[2169] \"unoppos\"         \"unpopular\"       \"unpreced\"        \"unsaf\"          \n",
      "[2173] \"upgrad\"          \"uphold\"          \"upon\"            \"uptick\"         \n",
      "[2177] \"uranium\"         \"urban\"           \"urg\"             \"us\"             \n",
      "[2181] \"use\"             \"user\"            \"usual\"           \"util\"           \n",
      "[2185] \"v\"               \"vacanc\"          \"vacant\"          \"vacat\"          \n",
      "[2189] \"vaccin\"          \"valley\"          \"valu\"            \"van\"            \n",
      "[2193] \"various\"         \"vast\"            \"vehicl\"          \"verifi\"         \n",
      "[2197] \"version\"         \"vet\"             \"veteran\"         \"veto\"           \n",
      "[2201] \"via\"             \"vice\"            \"vicious\"         \"victim\"         \n",
      "[2205] \"victori\"         \"video\"           \"view\"            \"viewer\"         \n",
      "[2209] \"violat\"          \"violenc\"         \"violent\"         \"virtual\"        \n",
      "[2213] \"virus\"           \"visa\"            \"visit\"           \"visitor\"        \n",
      "[2217] \"voic\"            \"volunt\"          \"vote\"            \"voter\"          \n",
      "[2221] \"voucher\"         \"vs\"              \"w\"               \"wade\"           \n",
      "[2225] \"wage\"            \"wait\"            \"waiv\"            \"waiver\"         \n",
      "[2229] \"walk\"            \"walker\"          \"wall\"            \"want\"           \n",
      "[2233] \"war\"             \"warm\"            \"warn\"            \"warrant\"        \n",
      "[2237] \"warren\"          \"wash\"            \"wast\"            \"watch\"          \n",
      "[2241] \"water\"           \"waterboard\"      \"way\"             \"weak\"           \n",
      "[2245] \"weaken\"          \"wealth\"          \"wealthi\"         \"weapon\"         \n",
      "[2249] \"wear\"            \"weather\"         \"websit\"          \"wed\"            \n",
      "[2253] \"week\"            \"weekend\"         \"welcom\"          \"welfar\"         \n",
      "[2257] \"west\"            \"western\"         \"what\"            \"whatev\"         \n",
      "[2261] \"whatsoev\"        \"whether\"         \"white\"           \"whitewat\"       \n",
      "[2265] \"whole\"           \"whop\"            \"whose\"           \"wide\"           \n",
      "[2269] \"wife\"            \"wild\"            \"wildlif\"         \"will\"           \n",
      "[2273] \"win\"             \"wind\"            \"window\"          \"winter\"         \n",
      "[2277] \"wipe\"            \"wish\"            \"wit\"             \"withdraw\"       \n",
      "[2281] \"within\"          \"without\"         \"wolf\"            \"woman\"          \n",
      "[2285] \"wont\"            \"word\"            \"work\"            \"worker\"         \n",
      "[2289] \"workforc\"        \"workman\"         \"workplac\"        \"world\"          \n",
      "[2293] \"worldwid\"        \"worri\"           \"worth\"           \"wound\"          \n",
      "[2297] \"wright\"          \"write\"           \"wrong\"           \"year\"           \n",
      "[2301] \"yes\"             \"yet\"             \"young\"           \"youth\"          \n",
      "[2305] \"zero\"            \"zone\"           \n"
     ]
    }
   ],
   "source": [
    "print(model$vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5 \n",
      "0.0820656 0.1907886 0.1624564 0.2092114 0.1912073 0.1642708 \n"
     ]
    }
   ],
   "source": [
    "print(model$prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2306 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>0</th><th scope=col>1</th><th scope=col>2</th><th scope=col>3</th><th scope=col>4</th><th scope=col>5</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>2</th><td>0.000142288</td><td>5.224660e-04</td><td>3.191320e-04</td><td>6.292474e-04</td><td>9.793634e-04</td><td>4.029658e-04</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.000142288</td><td>2.239140e-04</td><td>3.989150e-04</td><td>5.663227e-04</td><td>4.197272e-04</td><td>4.029658e-04</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.000142288</td><td>2.985520e-04</td><td>7.978299e-05</td><td>1.258495e-04</td><td>2.798181e-04</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.000142288</td><td>1.492760e-04</td><td>7.978299e-05</td><td>1.887742e-04</td><td>3.497726e-04</td><td>2.417795e-04</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.000142288</td><td>7.463801e-05</td><td>1.595660e-04</td><td>6.292474e-05</td><td>2.098636e-04</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>0.000142288</td><td>1.492760e-04</td><td>1.595660e-04</td><td>1.258495e-04</td><td>1.399091e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>abil</th><td>0.000142288</td><td>3.731900e-04</td><td>3.191320e-04</td><td>2.516990e-04</td><td>4.197272e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>abl</th><td>0.000284576</td><td>5.224660e-04</td><td>5.584809e-04</td><td>3.146237e-04</td><td>7.694998e-04</td><td>3.223727e-04</td></tr>\n",
       "\t<tr><th scope=row>abolish</th><td>0.000142288</td><td>5.224660e-04</td><td>7.978299e-05</td><td>1.887742e-04</td><td>6.995453e-05</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>abort</th><td>0.001280592</td><td>1.642036e-03</td><td>1.755226e-03</td><td>1.887742e-03</td><td>6.295908e-04</td><td>1.450677e-03</td></tr>\n",
       "\t<tr><th scope=row>absente</th><td>0.000142288</td><td>1.492760e-04</td><td>7.978299e-05</td><td>1.258495e-04</td><td>1.399091e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>absolut</th><td>0.000569152</td><td>1.492760e-04</td><td>1.595660e-04</td><td>1.258495e-04</td><td>2.798181e-04</td><td>2.417795e-04</td></tr>\n",
       "\t<tr><th scope=row>abus</th><td>0.000284576</td><td>2.985520e-04</td><td>1.595660e-04</td><td>1.258495e-04</td><td>1.399091e-04</td><td>6.447453e-04</td></tr>\n",
       "\t<tr><th scope=row>academ</th><td>0.000142288</td><td>1.492760e-04</td><td>2.393490e-04</td><td>6.292474e-05</td><td>1.399091e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>academi</th><td>0.000142288</td><td>7.463801e-05</td><td>2.393490e-04</td><td>6.292474e-05</td><td>3.497726e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>accept</th><td>0.000426864</td><td>2.239140e-04</td><td>5.584809e-04</td><td>3.775485e-04</td><td>3.497726e-04</td><td>3.223727e-04</td></tr>\n",
       "\t<tr><th scope=row>access</th><td>0.000426864</td><td>3.731900e-04</td><td>5.584809e-04</td><td>5.033979e-04</td><td>4.197272e-04</td><td>4.835590e-04</td></tr>\n",
       "\t<tr><th scope=row>accid</th><td>0.000142288</td><td>7.463801e-05</td><td>7.978299e-05</td><td>2.516990e-04</td><td>2.098636e-04</td><td>4.029658e-04</td></tr>\n",
       "\t<tr><th scope=row>accord</th><td>0.000711440</td><td>3.731900e-04</td><td>4.786979e-04</td><td>4.404732e-04</td><td>6.295908e-04</td><td>5.641522e-04</td></tr>\n",
       "\t<tr><th scope=row>account</th><td>0.000426864</td><td>2.985520e-04</td><td>4.786979e-04</td><td>3.146237e-04</td><td>7.694998e-04</td><td>8.865248e-04</td></tr>\n",
       "\t<tr><th scope=row>accumul</th><td>0.000142288</td><td>7.463801e-05</td><td>2.393490e-04</td><td>1.258495e-04</td><td>6.995453e-05</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>accus</th><td>0.000426864</td><td>1.492760e-04</td><td>7.978299e-05</td><td>1.258495e-04</td><td>2.798181e-04</td><td>2.417795e-04</td></tr>\n",
       "\t<tr><th scope=row>achiev</th><td>0.000284576</td><td>1.492760e-04</td><td>1.595660e-04</td><td>1.258495e-04</td><td>3.497726e-04</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>acknowledg</th><td>0.000142288</td><td>7.463801e-05</td><td>1.595660e-04</td><td>1.258495e-04</td><td>6.995453e-05</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>acorn</th><td>0.000142288</td><td>2.239140e-04</td><td>7.978299e-05</td><td>1.887742e-04</td><td>6.995453e-05</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>acr</th><td>0.000142288</td><td>2.239140e-04</td><td>7.978299e-05</td><td>2.516990e-04</td><td>2.798181e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>across</th><td>0.000569152</td><td>3.731900e-04</td><td>2.393490e-04</td><td>5.663227e-04</td><td>5.596362e-04</td><td>6.447453e-04</td></tr>\n",
       "\t<tr><th scope=row>act</th><td>0.000711440</td><td>1.268846e-03</td><td>1.276528e-03</td><td>1.950667e-03</td><td>1.469045e-03</td><td>7.253385e-04</td></tr>\n",
       "\t<tr><th scope=row>action</th><td>0.000426864</td><td>4.478280e-04</td><td>7.180469e-04</td><td>5.663227e-04</td><td>6.295908e-04</td><td>3.223727e-04</td></tr>\n",
       "\t<tr><th scope=row>activ</th><td>0.000569152</td><td>3.731900e-04</td><td>2.393490e-04</td><td>4.404732e-04</td><td>3.497726e-04</td><td>2.417795e-04</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>wipe</th><td>0.000142288</td><td>2.985520e-04</td><td>3.191320e-04</td><td>3.146237e-04</td><td>1.399091e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>wish</th><td>0.000142288</td><td>2.239140e-04</td><td>7.978299e-05</td><td>1.258495e-04</td><td>1.399091e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>wit</th><td>0.000142288</td><td>1.492760e-04</td><td>1.595660e-04</td><td>1.258495e-04</td><td>2.098636e-04</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>withdraw</th><td>0.000142288</td><td>3.731900e-04</td><td>3.191320e-04</td><td>1.887742e-04</td><td>1.399091e-04</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>within</th><td>0.000284576</td><td>5.971040e-04</td><td>2.393490e-04</td><td>3.146237e-04</td><td>4.197272e-04</td><td>8.059317e-04</td></tr>\n",
       "\t<tr><th scope=row>without</th><td>0.000426864</td><td>1.567398e-03</td><td>9.573959e-04</td><td>1.447269e-03</td><td>1.119272e-03</td><td>1.208897e-03</td></tr>\n",
       "\t<tr><th scope=row>wolf</th><td>0.000142288</td><td>1.492760e-04</td><td>1.595660e-04</td><td>6.292474e-05</td><td>6.995453e-05</td><td>2.417795e-04</td></tr>\n",
       "\t<tr><th scope=row>woman</th><td>0.001280592</td><td>2.089864e-03</td><td>2.792405e-03</td><td>1.384344e-03</td><td>2.098636e-03</td><td>2.176015e-03</td></tr>\n",
       "\t<tr><th scope=row>wont</th><td>0.000426864</td><td>2.239140e-04</td><td>3.989150e-04</td><td>1.887742e-04</td><td>2.798181e-04</td><td>4.029658e-04</td></tr>\n",
       "\t<tr><th scope=row>word</th><td>0.000569152</td><td>1.492760e-04</td><td>2.393490e-04</td><td>3.146237e-04</td><td>2.798181e-04</td><td>8.059317e-04</td></tr>\n",
       "\t<tr><th scope=row>work</th><td>0.002134320</td><td>2.463054e-03</td><td>2.074358e-03</td><td>3.335011e-03</td><td>2.238545e-03</td><td>1.128304e-03</td></tr>\n",
       "\t<tr><th scope=row>worker</th><td>0.000569152</td><td>1.194208e-03</td><td>1.835009e-03</td><td>1.447269e-03</td><td>1.818818e-03</td><td>1.208897e-03</td></tr>\n",
       "\t<tr><th scope=row>workforc</th><td>0.000142288</td><td>2.239140e-04</td><td>3.989150e-04</td><td>1.887742e-04</td><td>4.197272e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>workman</th><td>0.000142288</td><td>2.985520e-04</td><td>7.978299e-05</td><td>1.887742e-04</td><td>6.995453e-05</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>workplac</th><td>0.000142288</td><td>2.239140e-04</td><td>1.595660e-04</td><td>1.258495e-04</td><td>6.995453e-05</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>world</th><td>0.001565168</td><td>1.492760e-03</td><td>1.037179e-03</td><td>2.013592e-03</td><td>2.378454e-03</td><td>1.208897e-03</td></tr>\n",
       "\t<tr><th scope=row>worldwid</th><td>0.000284576</td><td>7.463801e-05</td><td>1.595660e-04</td><td>1.258495e-04</td><td>6.995453e-05</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>worri</th><td>0.000284576</td><td>7.463801e-05</td><td>7.978299e-05</td><td>2.516990e-04</td><td>1.399091e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>worth</th><td>0.000284576</td><td>2.239140e-04</td><td>7.978299e-05</td><td>5.663227e-04</td><td>4.896817e-04</td><td>7.253385e-04</td></tr>\n",
       "\t<tr><th scope=row>wound</th><td>0.000142288</td><td>7.463801e-05</td><td>2.393490e-04</td><td>2.516990e-04</td><td>1.399091e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>wright</th><td>0.000142288</td><td>7.463801e-05</td><td>1.595660e-04</td><td>6.292474e-05</td><td>2.098636e-04</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>write</th><td>0.000711440</td><td>5.224660e-04</td><td>4.786979e-04</td><td>6.292474e-04</td><td>5.596362e-04</td><td>4.029658e-04</td></tr>\n",
       "\t<tr><th scope=row>wrong</th><td>0.000142288</td><td>2.985520e-04</td><td>1.595660e-04</td><td>1.258495e-04</td><td>2.798181e-04</td><td>3.223727e-04</td></tr>\n",
       "\t<tr><th scope=row>year</th><td>0.005549232</td><td>1.022541e-02</td><td>1.085049e-02</td><td>1.151523e-02</td><td>1.238195e-02</td><td>1.168601e-02</td></tr>\n",
       "\t<tr><th scope=row>yes</th><td>0.000284576</td><td>3.731900e-04</td><td>1.595660e-04</td><td>1.887742e-04</td><td>6.995453e-05</td><td>8.059317e-05</td></tr>\n",
       "\t<tr><th scope=row>yet</th><td>0.000569152</td><td>2.239140e-04</td><td>4.786979e-04</td><td>5.033979e-04</td><td>3.497726e-04</td><td>4.029658e-04</td></tr>\n",
       "\t<tr><th scope=row>young</th><td>0.000426864</td><td>8.956561e-04</td><td>3.989150e-04</td><td>8.180216e-04</td><td>6.295908e-04</td><td>7.253385e-04</td></tr>\n",
       "\t<tr><th scope=row>youth</th><td>0.000142288</td><td>1.492760e-04</td><td>1.595660e-04</td><td>1.887742e-04</td><td>2.798181e-04</td><td>1.611863e-04</td></tr>\n",
       "\t<tr><th scope=row>zero</th><td>0.000569152</td><td>2.239140e-04</td><td>3.191320e-04</td><td>3.146237e-04</td><td>5.596362e-04</td><td>8.059317e-04</td></tr>\n",
       "\t<tr><th scope=row>zone</th><td>0.000426864</td><td>7.463801e-05</td><td>1.595660e-04</td><td>4.404732e-04</td><td>6.995453e-05</td><td>1.611863e-04</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2306 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & 0 & 1 & 2 & 3 & 4 & 5\\\\\n",
       "\\hline\n",
       "\t2 & 0.000142288 & 5.224660e-04 & 3.191320e-04 & 6.292474e-04 & 9.793634e-04 & 4.029658e-04\\\\\n",
       "\t3 & 0.000142288 & 2.239140e-04 & 3.989150e-04 & 5.663227e-04 & 4.197272e-04 & 4.029658e-04\\\\\n",
       "\t4 & 0.000142288 & 2.985520e-04 & 7.978299e-05 & 1.258495e-04 & 2.798181e-04 & 1.611863e-04\\\\\n",
       "\t5 & 0.000142288 & 1.492760e-04 & 7.978299e-05 & 1.887742e-04 & 3.497726e-04 & 2.417795e-04\\\\\n",
       "\t6 & 0.000142288 & 7.463801e-05 & 1.595660e-04 & 6.292474e-05 & 2.098636e-04 & 1.611863e-04\\\\\n",
       "\t9 & 0.000142288 & 1.492760e-04 & 1.595660e-04 & 1.258495e-04 & 1.399091e-04 & 8.059317e-05\\\\\n",
       "\tabil & 0.000142288 & 3.731900e-04 & 3.191320e-04 & 2.516990e-04 & 4.197272e-04 & 8.059317e-05\\\\\n",
       "\tabl & 0.000284576 & 5.224660e-04 & 5.584809e-04 & 3.146237e-04 & 7.694998e-04 & 3.223727e-04\\\\\n",
       "\tabolish & 0.000142288 & 5.224660e-04 & 7.978299e-05 & 1.887742e-04 & 6.995453e-05 & 1.611863e-04\\\\\n",
       "\tabort & 0.001280592 & 1.642036e-03 & 1.755226e-03 & 1.887742e-03 & 6.295908e-04 & 1.450677e-03\\\\\n",
       "\tabsente & 0.000142288 & 1.492760e-04 & 7.978299e-05 & 1.258495e-04 & 1.399091e-04 & 8.059317e-05\\\\\n",
       "\tabsolut & 0.000569152 & 1.492760e-04 & 1.595660e-04 & 1.258495e-04 & 2.798181e-04 & 2.417795e-04\\\\\n",
       "\tabus & 0.000284576 & 2.985520e-04 & 1.595660e-04 & 1.258495e-04 & 1.399091e-04 & 6.447453e-04\\\\\n",
       "\tacadem & 0.000142288 & 1.492760e-04 & 2.393490e-04 & 6.292474e-05 & 1.399091e-04 & 8.059317e-05\\\\\n",
       "\tacademi & 0.000142288 & 7.463801e-05 & 2.393490e-04 & 6.292474e-05 & 3.497726e-04 & 8.059317e-05\\\\\n",
       "\taccept & 0.000426864 & 2.239140e-04 & 5.584809e-04 & 3.775485e-04 & 3.497726e-04 & 3.223727e-04\\\\\n",
       "\taccess & 0.000426864 & 3.731900e-04 & 5.584809e-04 & 5.033979e-04 & 4.197272e-04 & 4.835590e-04\\\\\n",
       "\taccid & 0.000142288 & 7.463801e-05 & 7.978299e-05 & 2.516990e-04 & 2.098636e-04 & 4.029658e-04\\\\\n",
       "\taccord & 0.000711440 & 3.731900e-04 & 4.786979e-04 & 4.404732e-04 & 6.295908e-04 & 5.641522e-04\\\\\n",
       "\taccount & 0.000426864 & 2.985520e-04 & 4.786979e-04 & 3.146237e-04 & 7.694998e-04 & 8.865248e-04\\\\\n",
       "\taccumul & 0.000142288 & 7.463801e-05 & 2.393490e-04 & 1.258495e-04 & 6.995453e-05 & 8.059317e-05\\\\\n",
       "\taccus & 0.000426864 & 1.492760e-04 & 7.978299e-05 & 1.258495e-04 & 2.798181e-04 & 2.417795e-04\\\\\n",
       "\tachiev & 0.000284576 & 1.492760e-04 & 1.595660e-04 & 1.258495e-04 & 3.497726e-04 & 1.611863e-04\\\\\n",
       "\tacknowledg & 0.000142288 & 7.463801e-05 & 1.595660e-04 & 1.258495e-04 & 6.995453e-05 & 1.611863e-04\\\\\n",
       "\tacorn & 0.000142288 & 2.239140e-04 & 7.978299e-05 & 1.887742e-04 & 6.995453e-05 & 1.611863e-04\\\\\n",
       "\tacr & 0.000142288 & 2.239140e-04 & 7.978299e-05 & 2.516990e-04 & 2.798181e-04 & 8.059317e-05\\\\\n",
       "\tacross & 0.000569152 & 3.731900e-04 & 2.393490e-04 & 5.663227e-04 & 5.596362e-04 & 6.447453e-04\\\\\n",
       "\tact & 0.000711440 & 1.268846e-03 & 1.276528e-03 & 1.950667e-03 & 1.469045e-03 & 7.253385e-04\\\\\n",
       "\taction & 0.000426864 & 4.478280e-04 & 7.180469e-04 & 5.663227e-04 & 6.295908e-04 & 3.223727e-04\\\\\n",
       "\tactiv & 0.000569152 & 3.731900e-04 & 2.393490e-04 & 4.404732e-04 & 3.497726e-04 & 2.417795e-04\\\\\n",
       "\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\twipe & 0.000142288 & 2.985520e-04 & 3.191320e-04 & 3.146237e-04 & 1.399091e-04 & 8.059317e-05\\\\\n",
       "\twish & 0.000142288 & 2.239140e-04 & 7.978299e-05 & 1.258495e-04 & 1.399091e-04 & 8.059317e-05\\\\\n",
       "\twit & 0.000142288 & 1.492760e-04 & 1.595660e-04 & 1.258495e-04 & 2.098636e-04 & 1.611863e-04\\\\\n",
       "\twithdraw & 0.000142288 & 3.731900e-04 & 3.191320e-04 & 1.887742e-04 & 1.399091e-04 & 1.611863e-04\\\\\n",
       "\twithin & 0.000284576 & 5.971040e-04 & 2.393490e-04 & 3.146237e-04 & 4.197272e-04 & 8.059317e-04\\\\\n",
       "\twithout & 0.000426864 & 1.567398e-03 & 9.573959e-04 & 1.447269e-03 & 1.119272e-03 & 1.208897e-03\\\\\n",
       "\twolf & 0.000142288 & 1.492760e-04 & 1.595660e-04 & 6.292474e-05 & 6.995453e-05 & 2.417795e-04\\\\\n",
       "\twoman & 0.001280592 & 2.089864e-03 & 2.792405e-03 & 1.384344e-03 & 2.098636e-03 & 2.176015e-03\\\\\n",
       "\twont & 0.000426864 & 2.239140e-04 & 3.989150e-04 & 1.887742e-04 & 2.798181e-04 & 4.029658e-04\\\\\n",
       "\tword & 0.000569152 & 1.492760e-04 & 2.393490e-04 & 3.146237e-04 & 2.798181e-04 & 8.059317e-04\\\\\n",
       "\twork & 0.002134320 & 2.463054e-03 & 2.074358e-03 & 3.335011e-03 & 2.238545e-03 & 1.128304e-03\\\\\n",
       "\tworker & 0.000569152 & 1.194208e-03 & 1.835009e-03 & 1.447269e-03 & 1.818818e-03 & 1.208897e-03\\\\\n",
       "\tworkforc & 0.000142288 & 2.239140e-04 & 3.989150e-04 & 1.887742e-04 & 4.197272e-04 & 8.059317e-05\\\\\n",
       "\tworkman & 0.000142288 & 2.985520e-04 & 7.978299e-05 & 1.887742e-04 & 6.995453e-05 & 1.611863e-04\\\\\n",
       "\tworkplac & 0.000142288 & 2.239140e-04 & 1.595660e-04 & 1.258495e-04 & 6.995453e-05 & 8.059317e-05\\\\\n",
       "\tworld & 0.001565168 & 1.492760e-03 & 1.037179e-03 & 2.013592e-03 & 2.378454e-03 & 1.208897e-03\\\\\n",
       "\tworldwid & 0.000284576 & 7.463801e-05 & 1.595660e-04 & 1.258495e-04 & 6.995453e-05 & 1.611863e-04\\\\\n",
       "\tworri & 0.000284576 & 7.463801e-05 & 7.978299e-05 & 2.516990e-04 & 1.399091e-04 & 8.059317e-05\\\\\n",
       "\tworth & 0.000284576 & 2.239140e-04 & 7.978299e-05 & 5.663227e-04 & 4.896817e-04 & 7.253385e-04\\\\\n",
       "\twound & 0.000142288 & 7.463801e-05 & 2.393490e-04 & 2.516990e-04 & 1.399091e-04 & 8.059317e-05\\\\\n",
       "\twright & 0.000142288 & 7.463801e-05 & 1.595660e-04 & 6.292474e-05 & 2.098636e-04 & 8.059317e-05\\\\\n",
       "\twrite & 0.000711440 & 5.224660e-04 & 4.786979e-04 & 6.292474e-04 & 5.596362e-04 & 4.029658e-04\\\\\n",
       "\twrong & 0.000142288 & 2.985520e-04 & 1.595660e-04 & 1.258495e-04 & 2.798181e-04 & 3.223727e-04\\\\\n",
       "\tyear & 0.005549232 & 1.022541e-02 & 1.085049e-02 & 1.151523e-02 & 1.238195e-02 & 1.168601e-02\\\\\n",
       "\tyes & 0.000284576 & 3.731900e-04 & 1.595660e-04 & 1.887742e-04 & 6.995453e-05 & 8.059317e-05\\\\\n",
       "\tyet & 0.000569152 & 2.239140e-04 & 4.786979e-04 & 5.033979e-04 & 3.497726e-04 & 4.029658e-04\\\\\n",
       "\tyoung & 0.000426864 & 8.956561e-04 & 3.989150e-04 & 8.180216e-04 & 6.295908e-04 & 7.253385e-04\\\\\n",
       "\tyouth & 0.000142288 & 1.492760e-04 & 1.595660e-04 & 1.887742e-04 & 2.798181e-04 & 1.611863e-04\\\\\n",
       "\tzero & 0.000569152 & 2.239140e-04 & 3.191320e-04 & 3.146237e-04 & 5.596362e-04 & 8.059317e-04\\\\\n",
       "\tzone & 0.000426864 & 7.463801e-05 & 1.595660e-04 & 4.404732e-04 & 6.995453e-05 & 1.611863e-04\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2306 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | 0 | 1 | 2 | 3 | 4 | 5 |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 2 | 0.000142288 | 5.224660e-04 | 3.191320e-04 | 6.292474e-04 | 9.793634e-04 | 4.029658e-04 |\n",
       "| 3 | 0.000142288 | 2.239140e-04 | 3.989150e-04 | 5.663227e-04 | 4.197272e-04 | 4.029658e-04 |\n",
       "| 4 | 0.000142288 | 2.985520e-04 | 7.978299e-05 | 1.258495e-04 | 2.798181e-04 | 1.611863e-04 |\n",
       "| 5 | 0.000142288 | 1.492760e-04 | 7.978299e-05 | 1.887742e-04 | 3.497726e-04 | 2.417795e-04 |\n",
       "| 6 | 0.000142288 | 7.463801e-05 | 1.595660e-04 | 6.292474e-05 | 2.098636e-04 | 1.611863e-04 |\n",
       "| 9 | 0.000142288 | 1.492760e-04 | 1.595660e-04 | 1.258495e-04 | 1.399091e-04 | 8.059317e-05 |\n",
       "| abil | 0.000142288 | 3.731900e-04 | 3.191320e-04 | 2.516990e-04 | 4.197272e-04 | 8.059317e-05 |\n",
       "| abl | 0.000284576 | 5.224660e-04 | 5.584809e-04 | 3.146237e-04 | 7.694998e-04 | 3.223727e-04 |\n",
       "| abolish | 0.000142288 | 5.224660e-04 | 7.978299e-05 | 1.887742e-04 | 6.995453e-05 | 1.611863e-04 |\n",
       "| abort | 0.001280592 | 1.642036e-03 | 1.755226e-03 | 1.887742e-03 | 6.295908e-04 | 1.450677e-03 |\n",
       "| absente | 0.000142288 | 1.492760e-04 | 7.978299e-05 | 1.258495e-04 | 1.399091e-04 | 8.059317e-05 |\n",
       "| absolut | 0.000569152 | 1.492760e-04 | 1.595660e-04 | 1.258495e-04 | 2.798181e-04 | 2.417795e-04 |\n",
       "| abus | 0.000284576 | 2.985520e-04 | 1.595660e-04 | 1.258495e-04 | 1.399091e-04 | 6.447453e-04 |\n",
       "| academ | 0.000142288 | 1.492760e-04 | 2.393490e-04 | 6.292474e-05 | 1.399091e-04 | 8.059317e-05 |\n",
       "| academi | 0.000142288 | 7.463801e-05 | 2.393490e-04 | 6.292474e-05 | 3.497726e-04 | 8.059317e-05 |\n",
       "| accept | 0.000426864 | 2.239140e-04 | 5.584809e-04 | 3.775485e-04 | 3.497726e-04 | 3.223727e-04 |\n",
       "| access | 0.000426864 | 3.731900e-04 | 5.584809e-04 | 5.033979e-04 | 4.197272e-04 | 4.835590e-04 |\n",
       "| accid | 0.000142288 | 7.463801e-05 | 7.978299e-05 | 2.516990e-04 | 2.098636e-04 | 4.029658e-04 |\n",
       "| accord | 0.000711440 | 3.731900e-04 | 4.786979e-04 | 4.404732e-04 | 6.295908e-04 | 5.641522e-04 |\n",
       "| account | 0.000426864 | 2.985520e-04 | 4.786979e-04 | 3.146237e-04 | 7.694998e-04 | 8.865248e-04 |\n",
       "| accumul | 0.000142288 | 7.463801e-05 | 2.393490e-04 | 1.258495e-04 | 6.995453e-05 | 8.059317e-05 |\n",
       "| accus | 0.000426864 | 1.492760e-04 | 7.978299e-05 | 1.258495e-04 | 2.798181e-04 | 2.417795e-04 |\n",
       "| achiev | 0.000284576 | 1.492760e-04 | 1.595660e-04 | 1.258495e-04 | 3.497726e-04 | 1.611863e-04 |\n",
       "| acknowledg | 0.000142288 | 7.463801e-05 | 1.595660e-04 | 1.258495e-04 | 6.995453e-05 | 1.611863e-04 |\n",
       "| acorn | 0.000142288 | 2.239140e-04 | 7.978299e-05 | 1.887742e-04 | 6.995453e-05 | 1.611863e-04 |\n",
       "| acr | 0.000142288 | 2.239140e-04 | 7.978299e-05 | 2.516990e-04 | 2.798181e-04 | 8.059317e-05 |\n",
       "| across | 0.000569152 | 3.731900e-04 | 2.393490e-04 | 5.663227e-04 | 5.596362e-04 | 6.447453e-04 |\n",
       "| act | 0.000711440 | 1.268846e-03 | 1.276528e-03 | 1.950667e-03 | 1.469045e-03 | 7.253385e-04 |\n",
       "| action | 0.000426864 | 4.478280e-04 | 7.180469e-04 | 5.663227e-04 | 6.295908e-04 | 3.223727e-04 |\n",
       "| activ | 0.000569152 | 3.731900e-04 | 2.393490e-04 | 4.404732e-04 | 3.497726e-04 | 2.417795e-04 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| wipe | 0.000142288 | 2.985520e-04 | 3.191320e-04 | 3.146237e-04 | 1.399091e-04 | 8.059317e-05 |\n",
       "| wish | 0.000142288 | 2.239140e-04 | 7.978299e-05 | 1.258495e-04 | 1.399091e-04 | 8.059317e-05 |\n",
       "| wit | 0.000142288 | 1.492760e-04 | 1.595660e-04 | 1.258495e-04 | 2.098636e-04 | 1.611863e-04 |\n",
       "| withdraw | 0.000142288 | 3.731900e-04 | 3.191320e-04 | 1.887742e-04 | 1.399091e-04 | 1.611863e-04 |\n",
       "| within | 0.000284576 | 5.971040e-04 | 2.393490e-04 | 3.146237e-04 | 4.197272e-04 | 8.059317e-04 |\n",
       "| without | 0.000426864 | 1.567398e-03 | 9.573959e-04 | 1.447269e-03 | 1.119272e-03 | 1.208897e-03 |\n",
       "| wolf | 0.000142288 | 1.492760e-04 | 1.595660e-04 | 6.292474e-05 | 6.995453e-05 | 2.417795e-04 |\n",
       "| woman | 0.001280592 | 2.089864e-03 | 2.792405e-03 | 1.384344e-03 | 2.098636e-03 | 2.176015e-03 |\n",
       "| wont | 0.000426864 | 2.239140e-04 | 3.989150e-04 | 1.887742e-04 | 2.798181e-04 | 4.029658e-04 |\n",
       "| word | 0.000569152 | 1.492760e-04 | 2.393490e-04 | 3.146237e-04 | 2.798181e-04 | 8.059317e-04 |\n",
       "| work | 0.002134320 | 2.463054e-03 | 2.074358e-03 | 3.335011e-03 | 2.238545e-03 | 1.128304e-03 |\n",
       "| worker | 0.000569152 | 1.194208e-03 | 1.835009e-03 | 1.447269e-03 | 1.818818e-03 | 1.208897e-03 |\n",
       "| workforc | 0.000142288 | 2.239140e-04 | 3.989150e-04 | 1.887742e-04 | 4.197272e-04 | 8.059317e-05 |\n",
       "| workman | 0.000142288 | 2.985520e-04 | 7.978299e-05 | 1.887742e-04 | 6.995453e-05 | 1.611863e-04 |\n",
       "| workplac | 0.000142288 | 2.239140e-04 | 1.595660e-04 | 1.258495e-04 | 6.995453e-05 | 8.059317e-05 |\n",
       "| world | 0.001565168 | 1.492760e-03 | 1.037179e-03 | 2.013592e-03 | 2.378454e-03 | 1.208897e-03 |\n",
       "| worldwid | 0.000284576 | 7.463801e-05 | 1.595660e-04 | 1.258495e-04 | 6.995453e-05 | 1.611863e-04 |\n",
       "| worri | 0.000284576 | 7.463801e-05 | 7.978299e-05 | 2.516990e-04 | 1.399091e-04 | 8.059317e-05 |\n",
       "| worth | 0.000284576 | 2.239140e-04 | 7.978299e-05 | 5.663227e-04 | 4.896817e-04 | 7.253385e-04 |\n",
       "| wound | 0.000142288 | 7.463801e-05 | 2.393490e-04 | 2.516990e-04 | 1.399091e-04 | 8.059317e-05 |\n",
       "| wright | 0.000142288 | 7.463801e-05 | 1.595660e-04 | 6.292474e-05 | 2.098636e-04 | 8.059317e-05 |\n",
       "| write | 0.000711440 | 5.224660e-04 | 4.786979e-04 | 6.292474e-04 | 5.596362e-04 | 4.029658e-04 |\n",
       "| wrong | 0.000142288 | 2.985520e-04 | 1.595660e-04 | 1.258495e-04 | 2.798181e-04 | 3.223727e-04 |\n",
       "| year | 0.005549232 | 1.022541e-02 | 1.085049e-02 | 1.151523e-02 | 1.238195e-02 | 1.168601e-02 |\n",
       "| yes | 0.000284576 | 3.731900e-04 | 1.595660e-04 | 1.887742e-04 | 6.995453e-05 | 8.059317e-05 |\n",
       "| yet | 0.000569152 | 2.239140e-04 | 4.786979e-04 | 5.033979e-04 | 3.497726e-04 | 4.029658e-04 |\n",
       "| young | 0.000426864 | 8.956561e-04 | 3.989150e-04 | 8.180216e-04 | 6.295908e-04 | 7.253385e-04 |\n",
       "| youth | 0.000142288 | 1.492760e-04 | 1.595660e-04 | 1.887742e-04 | 2.798181e-04 | 1.611863e-04 |\n",
       "| zero | 0.000569152 | 2.239140e-04 | 3.191320e-04 | 3.146237e-04 | 5.596362e-04 | 8.059317e-04 |\n",
       "| zone | 0.000426864 | 7.463801e-05 | 1.595660e-04 | 4.404732e-04 | 6.995453e-05 | 1.611863e-04 |\n",
       "\n"
      ],
      "text/plain": [
       "           0           1            2            3            4           \n",
       "2          0.000142288 5.224660e-04 3.191320e-04 6.292474e-04 9.793634e-04\n",
       "3          0.000142288 2.239140e-04 3.989150e-04 5.663227e-04 4.197272e-04\n",
       "4          0.000142288 2.985520e-04 7.978299e-05 1.258495e-04 2.798181e-04\n",
       "5          0.000142288 1.492760e-04 7.978299e-05 1.887742e-04 3.497726e-04\n",
       "6          0.000142288 7.463801e-05 1.595660e-04 6.292474e-05 2.098636e-04\n",
       "9          0.000142288 1.492760e-04 1.595660e-04 1.258495e-04 1.399091e-04\n",
       "abil       0.000142288 3.731900e-04 3.191320e-04 2.516990e-04 4.197272e-04\n",
       "abl        0.000284576 5.224660e-04 5.584809e-04 3.146237e-04 7.694998e-04\n",
       "abolish    0.000142288 5.224660e-04 7.978299e-05 1.887742e-04 6.995453e-05\n",
       "abort      0.001280592 1.642036e-03 1.755226e-03 1.887742e-03 6.295908e-04\n",
       "absente    0.000142288 1.492760e-04 7.978299e-05 1.258495e-04 1.399091e-04\n",
       "absolut    0.000569152 1.492760e-04 1.595660e-04 1.258495e-04 2.798181e-04\n",
       "abus       0.000284576 2.985520e-04 1.595660e-04 1.258495e-04 1.399091e-04\n",
       "academ     0.000142288 1.492760e-04 2.393490e-04 6.292474e-05 1.399091e-04\n",
       "academi    0.000142288 7.463801e-05 2.393490e-04 6.292474e-05 3.497726e-04\n",
       "accept     0.000426864 2.239140e-04 5.584809e-04 3.775485e-04 3.497726e-04\n",
       "access     0.000426864 3.731900e-04 5.584809e-04 5.033979e-04 4.197272e-04\n",
       "accid      0.000142288 7.463801e-05 7.978299e-05 2.516990e-04 2.098636e-04\n",
       "accord     0.000711440 3.731900e-04 4.786979e-04 4.404732e-04 6.295908e-04\n",
       "account    0.000426864 2.985520e-04 4.786979e-04 3.146237e-04 7.694998e-04\n",
       "accumul    0.000142288 7.463801e-05 2.393490e-04 1.258495e-04 6.995453e-05\n",
       "accus      0.000426864 1.492760e-04 7.978299e-05 1.258495e-04 2.798181e-04\n",
       "achiev     0.000284576 1.492760e-04 1.595660e-04 1.258495e-04 3.497726e-04\n",
       "acknowledg 0.000142288 7.463801e-05 1.595660e-04 1.258495e-04 6.995453e-05\n",
       "acorn      0.000142288 2.239140e-04 7.978299e-05 1.887742e-04 6.995453e-05\n",
       "acr        0.000142288 2.239140e-04 7.978299e-05 2.516990e-04 2.798181e-04\n",
       "across     0.000569152 3.731900e-04 2.393490e-04 5.663227e-04 5.596362e-04\n",
       "act        0.000711440 1.268846e-03 1.276528e-03 1.950667e-03 1.469045e-03\n",
       "action     0.000426864 4.478280e-04 7.180469e-04 5.663227e-04 6.295908e-04\n",
       "activ      0.000569152 3.731900e-04 2.393490e-04 4.404732e-04 3.497726e-04\n",
       "⋮          ⋮           ⋮            ⋮            ⋮            ⋮           \n",
       "wipe       0.000142288 2.985520e-04 3.191320e-04 3.146237e-04 1.399091e-04\n",
       "wish       0.000142288 2.239140e-04 7.978299e-05 1.258495e-04 1.399091e-04\n",
       "wit        0.000142288 1.492760e-04 1.595660e-04 1.258495e-04 2.098636e-04\n",
       "withdraw   0.000142288 3.731900e-04 3.191320e-04 1.887742e-04 1.399091e-04\n",
       "within     0.000284576 5.971040e-04 2.393490e-04 3.146237e-04 4.197272e-04\n",
       "without    0.000426864 1.567398e-03 9.573959e-04 1.447269e-03 1.119272e-03\n",
       "wolf       0.000142288 1.492760e-04 1.595660e-04 6.292474e-05 6.995453e-05\n",
       "woman      0.001280592 2.089864e-03 2.792405e-03 1.384344e-03 2.098636e-03\n",
       "wont       0.000426864 2.239140e-04 3.989150e-04 1.887742e-04 2.798181e-04\n",
       "word       0.000569152 1.492760e-04 2.393490e-04 3.146237e-04 2.798181e-04\n",
       "work       0.002134320 2.463054e-03 2.074358e-03 3.335011e-03 2.238545e-03\n",
       "worker     0.000569152 1.194208e-03 1.835009e-03 1.447269e-03 1.818818e-03\n",
       "workforc   0.000142288 2.239140e-04 3.989150e-04 1.887742e-04 4.197272e-04\n",
       "workman    0.000142288 2.985520e-04 7.978299e-05 1.887742e-04 6.995453e-05\n",
       "workplac   0.000142288 2.239140e-04 1.595660e-04 1.258495e-04 6.995453e-05\n",
       "world      0.001565168 1.492760e-03 1.037179e-03 2.013592e-03 2.378454e-03\n",
       "worldwid   0.000284576 7.463801e-05 1.595660e-04 1.258495e-04 6.995453e-05\n",
       "worri      0.000284576 7.463801e-05 7.978299e-05 2.516990e-04 1.399091e-04\n",
       "worth      0.000284576 2.239140e-04 7.978299e-05 5.663227e-04 4.896817e-04\n",
       "wound      0.000142288 7.463801e-05 2.393490e-04 2.516990e-04 1.399091e-04\n",
       "wright     0.000142288 7.463801e-05 1.595660e-04 6.292474e-05 2.098636e-04\n",
       "write      0.000711440 5.224660e-04 4.786979e-04 6.292474e-04 5.596362e-04\n",
       "wrong      0.000142288 2.985520e-04 1.595660e-04 1.258495e-04 2.798181e-04\n",
       "year       0.005549232 1.022541e-02 1.085049e-02 1.151523e-02 1.238195e-02\n",
       "yes        0.000284576 3.731900e-04 1.595660e-04 1.887742e-04 6.995453e-05\n",
       "yet        0.000569152 2.239140e-04 4.786979e-04 5.033979e-04 3.497726e-04\n",
       "young      0.000426864 8.956561e-04 3.989150e-04 8.180216e-04 6.295908e-04\n",
       "youth      0.000142288 1.492760e-04 1.595660e-04 1.887742e-04 2.798181e-04\n",
       "zero       0.000569152 2.239140e-04 3.191320e-04 3.146237e-04 5.596362e-04\n",
       "zone       0.000426864 7.463801e-05 1.595660e-04 4.404732e-04 6.995453e-05\n",
       "           5           \n",
       "2          4.029658e-04\n",
       "3          4.029658e-04\n",
       "4          1.611863e-04\n",
       "5          2.417795e-04\n",
       "6          1.611863e-04\n",
       "9          8.059317e-05\n",
       "abil       8.059317e-05\n",
       "abl        3.223727e-04\n",
       "abolish    1.611863e-04\n",
       "abort      1.450677e-03\n",
       "absente    8.059317e-05\n",
       "absolut    2.417795e-04\n",
       "abus       6.447453e-04\n",
       "academ     8.059317e-05\n",
       "academi    8.059317e-05\n",
       "accept     3.223727e-04\n",
       "access     4.835590e-04\n",
       "accid      4.029658e-04\n",
       "accord     5.641522e-04\n",
       "account    8.865248e-04\n",
       "accumul    8.059317e-05\n",
       "accus      2.417795e-04\n",
       "achiev     1.611863e-04\n",
       "acknowledg 1.611863e-04\n",
       "acorn      1.611863e-04\n",
       "acr        8.059317e-05\n",
       "across     6.447453e-04\n",
       "act        7.253385e-04\n",
       "action     3.223727e-04\n",
       "activ      2.417795e-04\n",
       "⋮          ⋮           \n",
       "wipe       8.059317e-05\n",
       "wish       8.059317e-05\n",
       "wit        1.611863e-04\n",
       "withdraw   1.611863e-04\n",
       "within     8.059317e-04\n",
       "without    1.208897e-03\n",
       "wolf       2.417795e-04\n",
       "woman      2.176015e-03\n",
       "wont       4.029658e-04\n",
       "word       8.059317e-04\n",
       "work       1.128304e-03\n",
       "worker     1.208897e-03\n",
       "workforc   8.059317e-05\n",
       "workman    1.611863e-04\n",
       "workplac   8.059317e-05\n",
       "world      1.208897e-03\n",
       "worldwid   1.611863e-04\n",
       "worri      8.059317e-05\n",
       "worth      7.253385e-04\n",
       "wound      8.059317e-05\n",
       "wright     8.059317e-05\n",
       "write      4.029658e-04\n",
       "wrong      3.223727e-04\n",
       "year       1.168601e-02\n",
       "yes        8.059317e-05\n",
       "yet        4.029658e-04\n",
       "young      7.253385e-04\n",
       "youth      1.611863e-04\n",
       "zero       8.059317e-04\n",
       "zone       1.611863e-04"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model$condprob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the result from the training to test the accuracy of the produced model on the validation set. The accuracy is simply defined as the number of the correct predicted labels; for a more deep analysis we also provide the confusion matrix, in order to see if specific patterns are present (for example a label which is predicted much more times than the others without any reason). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pred_labels <- sapply(validation_set$Text, function(doc) {\n",
    "  apply_multinomial_nb(classes, model$vocab, model$prior, model$condprob, doc)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1927083 \n",
      "\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Predicted\n",
      "True  0  1  2  3  4  5\n",
      "   0  8 18 22 35 26 16\n",
      "   1 19 64 47 84 68 33\n",
      "   2 11 53 50 59 45 21\n",
      "   3 16 56 46 80 81 42\n",
      "   4 17 67 43 64 69 45\n",
      "   5  9 56 33 60 48 25\n"
     ]
    }
   ],
   "source": [
    "correct_predictions <- sum(test_set$Label == pred_labels)\n",
    "total_predictions <- length(test_set$Label)\n",
    "accuracy <- correct_predictions / total_predictions\n",
    "confusion_matrix <- table(True = test_set$Label, Predicted = pred_labels)\n",
    "\n",
    "cat(\"Accuracy:\", accuracy, \"\\n\\n\")\n",
    "cat(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the accuracy obtained on the validation set is really low. Our model performs a little better than choosing at random (which will give an average accuracy of 0.167, 1 over 6), but obviously this result indicates that this methods is not capable of classifying well the documents. From the conclusion matrix we see that no specific pattern arises and in general we don't have a general behaviour that explains the misclassified documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning of the hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only parameter that we can tune using the validation set in this case is the occurrency threshold for our vocabulary. In order to find the best parameter, we can simply train different models and choose the one that maximizes the accuracy on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold:  2 \n",
      "Best accuracy:  0.1966146 \n"
     ]
    }
   ],
   "source": [
    "# SHOULD WE DO A FUNCTION FOR THIS???? FOR ME YES, IT'S REALLY EASY\n",
    "\n",
    "poss_thresholds <- 1:20\n",
    "accuracies <- numeric(length(poss_thresholds))\n",
    "\n",
    "for (i in seq_along(poss_thresholds)) {\n",
    "  model <- train_multinomial_nb(classes, training_set, threshold = poss_thresholds[[i]], type = \"Six\")\n",
    "  pred_labels <- sapply(validation_set$Text, function(doc) {\n",
    "    apply_multinomial_nb(classes, model$vocab, model$prior, model$condprob, doc)\n",
    "  })\n",
    "\n",
    "  correct_predictions <- sum(test_set$Label == pred_labels)\n",
    "  total_predictions <- length(test_set$Label)\n",
    "  accuracies[[i]] <- correct_predictions / total_predictions\n",
    "}\n",
    "\n",
    "best_threshold <- poss_thresholds[which.max(accuracies)]\n",
    "cat(\"Best threshold: \", best_threshold, \"\\n\")\n",
    "cat(\"Best accuracy: \", max(accuracies), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way we are able to tune the best threshold for our model: as we can see, even after a tuning, we still obtain a really small value for the accuracy, which indicates that this parameter is not the main responsable for the poor performances of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the choice of the bets hyper-parameters we proceed testing the model on unseen data, the test set. We train again the model with the best threshold for the vocabulary and then we study the accuracy on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model <- train_multinomial_nb(classes, training_set, best_threshold, type = \"Six\")\n",
    "\n",
    "pred_labels <- sapply(test_set$Text, function(doc) {\n",
    "  apply_multinomial_nb(classes, model$vocab, model$prior, model$condprob, doc)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2128906 \n",
      "\n",
      "Confusion Matrix:\n",
      "    Predicted\n",
      "True  0  1  2  3  4  5\n",
      "   0 10 25 22 30 22 16\n",
      "   1 17 70 55 89 45 39\n",
      "   2  8 50 44 66 45 26\n",
      "   3 13 58 55 88 73 34\n",
      "   4 12 50 40 70 83 50\n",
      "   5  7 45 27 58 62 32\n"
     ]
    }
   ],
   "source": [
    "correct_predictions <- sum(test_set$Label == pred_labels)\n",
    "total_predictions <- length(test_set$Label)\n",
    "accuracy <- correct_predictions / total_predictions\n",
    "confusion_matrix <- table(True = test_set$Label, Predicted = pred_labels)\n",
    "\n",
    "cat(\"Accuracy:\", accuracy, \"\\n\\n\")\n",
    "cat(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this final analysis we obtain again a very low accuracy for our model; again no specific pattern can be deduced from the confusion matrix.\n",
    "\n",
    "One thing that in general we can conclude is that we don't have overfitting or underfitting as the training, the validation and the test errors are all similar. One possible cause of the poor performance is the small length of each document in the dataset, which makes hard for the model to classify only on the basis of a few words; at the same time, the presence of six different lables makes things more difficult for the model, as similar labels could share similar general patterns (this is amplified by the small number of words per document)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible reason for the poor performance of the model is a not enough large dataset for training and validation; in order to remove this possibility we proceed using the K-fold cross validation approach. In the following cells, we perform the same operations done in the previous points, studying possible values for the threshold. Moreover, this time we divide the dataset only in training set and test set, as the validation set is directly selected by the `kfold_cross_validation` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "eigthy_percent <- floor(length(dataset$Text) * 0.8)\n",
    "n <- nrow(dataset)\n",
    "\n",
    "dataset <- dataset[sample(n), ]\n",
    "\n",
    "training_set <- dataset[1:eigthy_percent, ]\n",
    "test_set <- dataset[(eigthy_percent + 1):n, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 20 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>threshold</th><th scope=col>mean_accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>0.2259010</td></tr>\n",
       "\t<tr><td> 2</td><td>0.2219914</td></tr>\n",
       "\t<tr><td> 3</td><td>0.2238241</td></tr>\n",
       "\t<tr><td> 4</td><td>0.2233354</td></tr>\n",
       "\t<tr><td> 5</td><td>0.2227245</td></tr>\n",
       "\t<tr><td> 6</td><td>0.2229688</td></tr>\n",
       "\t<tr><td> 7</td><td>0.2202810</td></tr>\n",
       "\t<tr><td> 8</td><td>0.2217471</td></tr>\n",
       "\t<tr><td> 9</td><td>0.2217471</td></tr>\n",
       "\t<tr><td>10</td><td>0.2224801</td></tr>\n",
       "\t<tr><td>11</td><td>0.2226023</td></tr>\n",
       "\t<tr><td>12</td><td>0.2237019</td></tr>\n",
       "\t<tr><td>13</td><td>0.2233354</td></tr>\n",
       "\t<tr><td>14</td><td>0.2227245</td></tr>\n",
       "\t<tr><td>15</td><td>0.2210141</td></tr>\n",
       "\t<tr><td>16</td><td>0.2218693</td></tr>\n",
       "\t<tr><td>17</td><td>0.2221136</td></tr>\n",
       "\t<tr><td>18</td><td>0.2230910</td></tr>\n",
       "\t<tr><td>19</td><td>0.2215027</td></tr>\n",
       "\t<tr><td>20</td><td>0.2222358</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 20 × 2\n",
       "\\begin{tabular}{ll}\n",
       " threshold & mean\\_accuracy\\\\\n",
       " <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & 0.2259010\\\\\n",
       "\t  2 & 0.2219914\\\\\n",
       "\t  3 & 0.2238241\\\\\n",
       "\t  4 & 0.2233354\\\\\n",
       "\t  5 & 0.2227245\\\\\n",
       "\t  6 & 0.2229688\\\\\n",
       "\t  7 & 0.2202810\\\\\n",
       "\t  8 & 0.2217471\\\\\n",
       "\t  9 & 0.2217471\\\\\n",
       "\t 10 & 0.2224801\\\\\n",
       "\t 11 & 0.2226023\\\\\n",
       "\t 12 & 0.2237019\\\\\n",
       "\t 13 & 0.2233354\\\\\n",
       "\t 14 & 0.2227245\\\\\n",
       "\t 15 & 0.2210141\\\\\n",
       "\t 16 & 0.2218693\\\\\n",
       "\t 17 & 0.2221136\\\\\n",
       "\t 18 & 0.2230910\\\\\n",
       "\t 19 & 0.2215027\\\\\n",
       "\t 20 & 0.2222358\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 20 × 2\n",
       "\n",
       "| threshold &lt;int&gt; | mean_accuracy &lt;dbl&gt; |\n",
       "|---|---|\n",
       "|  1 | 0.2259010 |\n",
       "|  2 | 0.2219914 |\n",
       "|  3 | 0.2238241 |\n",
       "|  4 | 0.2233354 |\n",
       "|  5 | 0.2227245 |\n",
       "|  6 | 0.2229688 |\n",
       "|  7 | 0.2202810 |\n",
       "|  8 | 0.2217471 |\n",
       "|  9 | 0.2217471 |\n",
       "| 10 | 0.2224801 |\n",
       "| 11 | 0.2226023 |\n",
       "| 12 | 0.2237019 |\n",
       "| 13 | 0.2233354 |\n",
       "| 14 | 0.2227245 |\n",
       "| 15 | 0.2210141 |\n",
       "| 16 | 0.2218693 |\n",
       "| 17 | 0.2221136 |\n",
       "| 18 | 0.2230910 |\n",
       "| 19 | 0.2215027 |\n",
       "| 20 | 0.2222358 |\n",
       "\n"
      ],
      "text/plain": [
       "   threshold mean_accuracy\n",
       "1   1        0.2259010    \n",
       "2   2        0.2219914    \n",
       "3   3        0.2238241    \n",
       "4   4        0.2233354    \n",
       "5   5        0.2227245    \n",
       "6   6        0.2229688    \n",
       "7   7        0.2202810    \n",
       "8   8        0.2217471    \n",
       "9   9        0.2217471    \n",
       "10 10        0.2224801    \n",
       "11 11        0.2226023    \n",
       "12 12        0.2237019    \n",
       "13 13        0.2233354    \n",
       "14 14        0.2227245    \n",
       "15 15        0.2210141    \n",
       "16 16        0.2218693    \n",
       "17 17        0.2221136    \n",
       "18 18        0.2230910    \n",
       "19 19        0.2215027    \n",
       "20 20        0.2222358    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poss_thresholds <- 1:20\n",
    "crossval_results <- kfold_cross_validation(training_set, k = 5, thresholds = poss_thresholds, type = \"Six\")\n",
    "crossval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_threshold <- crossval_results$threshold[which.max(crossval_results$mean_accuracy)]\n",
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model <- train_multinomial_nb(classes, training_set, best_threshold, type = \"Six\")\n",
    "pred_labels <- sapply(test_set$Text, function(doc) {\n",
    "  apply_multinomial_nb(classes, model$vocab, model$prior, model$condprob, doc)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2294922 \n",
      "\n",
      "Confusion Matrix:\n",
      "    Predicted\n",
      "True   0   1   2   3   4   5\n",
      "   0  18  49  21  38  27  15\n",
      "   1  10 100  59 106  78  45\n",
      "   2   7  67  56  98  68  36\n",
      "   3   8  81  49 128  98  50\n",
      "   4   2  52  32 133 114  59\n",
      "   5   7  54  33  90 106  54\n"
     ]
    }
   ],
   "source": [
    "correct_predictions <- sum(test_set$Label == pred_labels)\n",
    "total_predictions <- length(test_set$Label)\n",
    "accuracy <- correct_predictions / total_predictions\n",
    "confusion_matrix <- table(True = test_set$Label, Predicted = pred_labels)\n",
    "\n",
    "cat(\"Accuracy:\", accuracy, \"\\n\\n\")\n",
    "cat(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this approach we obtain similar results as before. Depending on the initial random shuffling of the dataset we obtain values of accuracies for the best threshold between 0.20 and 0.23, which is still an indicator of a very bad performance of our model. In any case, this result tells us that the k-fold cross validation doesn't change a lot the behaviour of the model; this could indicate the necessity of a different pre-processing technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis using tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approaches used up to this point have not produced a succesfull model. As already anticipated, probably the low number of words for document is one of the biggest problems for the performance of our model: for this reason, we leverage the presence of the column `Tag`, building the vocabulary in a different way. Rather than looking to all the document, we consider the different tags and build a different vocabulary for each tag: then we unify the vocabularies in a single one. The idea behind this process is that for different tags we have different main words and more words are under the threshold (and thus not considered).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "5141"
      ],
      "text/latex": [
       "5141"
      ],
      "text/markdown": [
       "5141"
      ],
      "text/plain": [
       "[1] 5141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# THIS DOESN'T WORK: IT SHOULD RETURN 21768, I DON'T UNDERSTAND WHY...\n",
    "# COULD IT BE SAME PROBLEM OF YESTERDAY?\n",
    "\n",
    "len_voc <- length(get_vocabulary_tags(dataset, threshold = 0))\n",
    "len_voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1149"
      ],
      "text/latex": [
       "1149"
      ],
      "text/markdown": [
       "1149"
      ],
      "text/plain": [
       "[1] 1149"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_voc <- length(get_vocabulary_tags(dataset, threshold = 5))\n",
    "len_voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using `threshold = 5` in this case we able to reduce the vocabulary to 5.3% of the initial vocabulary. Next, we proceed to a k-fold cross validation in order to select the best threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 21 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>threshold</th><th scope=col>mean_accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0</td><td>0.2260232</td></tr>\n",
       "\t<tr><td> 1</td><td>0.2260232</td></tr>\n",
       "\t<tr><td> 2</td><td>0.2222358</td></tr>\n",
       "\t<tr><td> 3</td><td>0.2215027</td></tr>\n",
       "\t<tr><td> 4</td><td>0.2215027</td></tr>\n",
       "\t<tr><td> 5</td><td>0.2224801</td></tr>\n",
       "\t<tr><td> 6</td><td>0.2223580</td></tr>\n",
       "\t<tr><td> 7</td><td>0.2230910</td></tr>\n",
       "\t<tr><td> 8</td><td>0.2263897</td></tr>\n",
       "\t<tr><td> 9</td><td>0.2279780</td></tr>\n",
       "\t<tr><td>10</td><td>0.2257789</td></tr>\n",
       "\t<tr><td>11</td><td>0.2240684</td></tr>\n",
       "\t<tr><td>12</td><td>0.2232132</td></tr>\n",
       "\t<tr><td>13</td><td>0.2229688</td></tr>\n",
       "\t<tr><td>14</td><td>0.2210141</td></tr>\n",
       "\t<tr><td>15</td><td>0.2199145</td></tr>\n",
       "\t<tr><td>16</td><td>0.2179597</td></tr>\n",
       "\t<tr><td>17</td><td>0.2199145</td></tr>\n",
       "\t<tr><td>18</td><td>0.2197923</td></tr>\n",
       "\t<tr><td>19</td><td>0.2179597</td></tr>\n",
       "\t<tr><td>20</td><td>0.2171045</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 21 × 2\n",
       "\\begin{tabular}{ll}\n",
       " threshold & mean\\_accuracy\\\\\n",
       " <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  0 & 0.2260232\\\\\n",
       "\t  1 & 0.2260232\\\\\n",
       "\t  2 & 0.2222358\\\\\n",
       "\t  3 & 0.2215027\\\\\n",
       "\t  4 & 0.2215027\\\\\n",
       "\t  5 & 0.2224801\\\\\n",
       "\t  6 & 0.2223580\\\\\n",
       "\t  7 & 0.2230910\\\\\n",
       "\t  8 & 0.2263897\\\\\n",
       "\t  9 & 0.2279780\\\\\n",
       "\t 10 & 0.2257789\\\\\n",
       "\t 11 & 0.2240684\\\\\n",
       "\t 12 & 0.2232132\\\\\n",
       "\t 13 & 0.2229688\\\\\n",
       "\t 14 & 0.2210141\\\\\n",
       "\t 15 & 0.2199145\\\\\n",
       "\t 16 & 0.2179597\\\\\n",
       "\t 17 & 0.2199145\\\\\n",
       "\t 18 & 0.2197923\\\\\n",
       "\t 19 & 0.2179597\\\\\n",
       "\t 20 & 0.2171045\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 21 × 2\n",
       "\n",
       "| threshold &lt;int&gt; | mean_accuracy &lt;dbl&gt; |\n",
       "|---|---|\n",
       "|  0 | 0.2260232 |\n",
       "|  1 | 0.2260232 |\n",
       "|  2 | 0.2222358 |\n",
       "|  3 | 0.2215027 |\n",
       "|  4 | 0.2215027 |\n",
       "|  5 | 0.2224801 |\n",
       "|  6 | 0.2223580 |\n",
       "|  7 | 0.2230910 |\n",
       "|  8 | 0.2263897 |\n",
       "|  9 | 0.2279780 |\n",
       "| 10 | 0.2257789 |\n",
       "| 11 | 0.2240684 |\n",
       "| 12 | 0.2232132 |\n",
       "| 13 | 0.2229688 |\n",
       "| 14 | 0.2210141 |\n",
       "| 15 | 0.2199145 |\n",
       "| 16 | 0.2179597 |\n",
       "| 17 | 0.2199145 |\n",
       "| 18 | 0.2197923 |\n",
       "| 19 | 0.2179597 |\n",
       "| 20 | 0.2171045 |\n",
       "\n"
      ],
      "text/plain": [
       "   threshold mean_accuracy\n",
       "1   0        0.2260232    \n",
       "2   1        0.2260232    \n",
       "3   2        0.2222358    \n",
       "4   3        0.2215027    \n",
       "5   4        0.2215027    \n",
       "6   5        0.2224801    \n",
       "7   6        0.2223580    \n",
       "8   7        0.2230910    \n",
       "9   8        0.2263897    \n",
       "10  9        0.2279780    \n",
       "11 10        0.2257789    \n",
       "12 11        0.2240684    \n",
       "13 12        0.2232132    \n",
       "14 13        0.2229688    \n",
       "15 14        0.2210141    \n",
       "16 15        0.2199145    \n",
       "17 16        0.2179597    \n",
       "18 17        0.2199145    \n",
       "19 18        0.2197923    \n",
       "20 19        0.2179597    \n",
       "21 20        0.2171045    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poss_thresholds <- 0:20\n",
    "crossval_results <- kfold_cross_validation(training_set, k = 5, thresholds = poss_thresholds, type = \"Tags\")\n",
    "crossval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_threshold <- crossval_results$threshold[which.max(crossval_results$mean_accuracy)]\n",
    "best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model <- train_multinomial_nb(classes, training_set, best_threshold, type = \"Tags\")\n",
    "pred_labels <- sapply(test_set$Text, function(doc) {\n",
    "  apply_multinomial_nb(classes, model$vocab, model$prior, model$condprob, doc)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2216797 \n",
      "\n",
      "Confusion Matrix:\n",
      "    Predicted\n",
      "True   0   1   2   3   4   5\n",
      "   0  17  55  26  35  15  20\n",
      "   1  18 102  56 113  61  48\n",
      "   2  16  76  64  90  51  35\n",
      "   3  13  78  73 121  75  54\n",
      "   4  10  67  40 109  95  71\n",
      "   5  12  72  39  71  95  55\n"
     ]
    }
   ],
   "source": [
    "correct_predictions <- sum(test_set$Label == pred_labels)\n",
    "total_predictions <- length(test_set$Label)\n",
    "accuracy <- correct_predictions / total_predictions\n",
    "confusion_matrix <- table(True = test_set$Label, Predicted = pred_labels)\n",
    "\n",
    "cat(\"Accuracy:\", accuracy, \"\\n\\n\")\n",
    "cat(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, also in this case, we are not able to achieve an accuracy higher than 25%, thus we can conclude that also this approach is not correct. The only thing that we can observe is that reducing the size of the vocabulary without any other kind of preprocessing doesn't really produce any gain in the accuracy; thus, this is probably not the best strategy for this dataset and other possibilities should be studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Two-label dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dataset <- read.csv(\"two_label_dataset.csv\", col.names = c(\"ID\", \"Title\", \"Author\", \"Text\", \"Label\"))\n",
    "classes <- as.integer(sort(unique(dataset$Label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dataset$Text <- clean(dataset$Text)\n",
    "dataset <- clean_empty_rows(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi è verificato un arresto anomalo del Kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. \n",
      "\u001b[1;31mEsaminare il codice nelle celle per identificare una possibile causa dell'errore. \n",
      "\u001b[1;31mPer altre informazioni, fare clic<a href='https://aka.ms/vscodeJupyterKernelCrash'>qui</a>. \n",
      "\u001b[1;31mPer ulteriori dettagli, visualizzare Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "eighty_percent <- as.integer(length(dataset$Text) * 0.8)\n",
    "\n",
    "training_set <- dataset[1:eighty_percent, ]\n",
    "test_set <- dataset[(eighty_percent + 1):length(dataset$Text), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "crossval_results <- kfold_cross_validation(training_set, k = 5, thresholds = c(1e-10, 1e-9, 5e-9, 1e-8, 5e-8, 1e-7, 5e-7, 1e-6, 5e-6, 1e-5, 1.6e-5, 2e-5, 5e-5), type = \"Two\")\n",
    "crossval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "best_threshold <- crossval_results$threshold[which.max(crossval_results$mean_accuracy)]\n",
    "model <- train_multinomial_nb(classes, training_set, best_threshold, type = \"Two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pred_labels <- sapply(test_set$Text, function(doc) {\n",
    "  apply_multinomial_nb(classes, model$vocab, model$prior, model$condprob, doc)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "correct_predictions <- sum(test_set$Label == pred_labels)\n",
    "total_predictions <- length(test_set$Label)\n",
    "accuracy <- correct_predictions / total_predictions\n",
    "confusion_matrix <- table(True = test_set$Label, Predicted = pred_labels)\n",
    "\n",
    "cat(\"Accuracy:\", accuracy, \"\\n\\n\")\n",
    "cat(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
